{
  "startup_times": {
    "total_time": {
      "mean": 1.2416,
      "median": 1.2247,
      "stdev": 0.03288631934406778,
      "min": 1.2206,
      "max": 1.2795,
      "runs": [
        1.2795,
        1.2247,
        1.2206
      ]
    },
    "config_time": {
      "mean": 0.03106666666666667,
      "median": 0.0308
    },
    "import_time": {
      "mean": 1.1893,
      "median": 1.1714
    },
    "ready_time": {
      "mean": 0.021266666666666666,
      "median": 0.0214
    }
  },
  "import_analysis": {
    "total_imports": 2575,
    "heaviest_imports": [
      {
        "module": "mcp_the_force.tools",
        "self_us": 141,
        "cumulative_us": 752542,
        "self_ms": 0.141,
        "cumulative_ms": 752.542
      },
      {
        "module": "mcp_the_force.tools.registry",
        "self_us": 615,
        "cumulative_us": 719250,
        "self_ms": 0.615,
        "cumulative_ms": 719.25
      },
      {
        "module": "mcp_the_force.adapters.capabilities",
        "self_us": 8,
        "cumulative_us": 717357,
        "self_ms": 0.008,
        "cumulative_ms": 717.357
      },
      {
        "module": "mcp_the_force.adapters",
        "self_us": 75,
        "cumulative_us": 717349,
        "self_ms": 0.075,
        "cumulative_ms": 717.349
      },
      {
        "module": "mcp_the_force.adapters.litellm_base",
        "self_us": 145,
        "cumulative_us": 717142,
        "self_ms": 0.145,
        "cumulative_ms": 717.142
      },
      {
        "module": "litellm",
        "self_us": 43607,
        "cumulative_us": 695881,
        "self_ms": 43.607,
        "cumulative_ms": 695.881
      },
      {
        "module": "litellm.llms.custom_httpx.http_handler",
        "self_us": 505,
        "cumulative_us": 313145,
        "self_ms": 0.505,
        "cumulative_ms": 313.145
      },
      {
        "module": "litellm.cost_calculator",
        "self_us": 375,
        "cumulative_us": 223435,
        "self_ms": 0.375,
        "cumulative_ms": 223.435
      },
      {
        "module": "mcp_the_force.tools.integration",
        "self_us": 146,
        "cumulative_us": 222814,
        "self_ms": 0.146,
        "cumulative_ms": 222.814
      },
      {
        "module": "litellm.litellm_core_utils.llm_cost_calc.utils",
        "self_us": 123,
        "cumulative_us": 219851,
        "self_ms": 0.123,
        "cumulative_ms": 219.851
      }
    ],
    "adapter_imports": [
      {
        "module": "mcp_the_force.adapters.capabilities",
        "self_us": 8,
        "cumulative_us": 717357,
        "self_ms": 0.008,
        "cumulative_ms": 717.357
      },
      {
        "module": "mcp_the_force.adapters",
        "self_us": 75,
        "cumulative_us": 717349,
        "self_ms": 0.075,
        "cumulative_ms": 717.349
      },
      {
        "module": "mcp_the_force.adapters.litellm_base",
        "self_us": 145,
        "cumulative_us": 717142,
        "self_ms": 0.145,
        "cumulative_ms": 717.142
      },
      {
        "module": "mcp_the_force.adapters.openai.adapter",
        "self_us": 145,
        "cumulative_us": 22043,
        "self_ms": 0.145,
        "cumulative_ms": 22.043
      },
      {
        "module": "mcp_the_force.adapters.openai.flow",
        "self_us": 465,
        "cumulative_us": 18151,
        "self_ms": 0.465,
        "cumulative_ms": 18.151
      },
      {
        "module": "importlib.metadata._adapters",
        "self_us": 180,
        "cumulative_us": 6984,
        "self_ms": 0.18,
        "cumulative_ms": 6.984
      },
      {
        "module": "requests.adapters",
        "self_us": 4026,
        "cumulative_us": 5394,
        "self_ms": 4.026,
        "cumulative_ms": 5.394
      },
      {
        "module": "mcp_the_force.adapters.openai.models",
        "self_us": 5080,
        "cumulative_us": 5080,
        "self_ms": 5.08,
        "cumulative_ms": 5.08
      },
      {
        "module": "mcp_the_force.adapters.openai.definitions",
        "self_us": 3601,
        "cumulative_us": 3748,
        "self_ms": 3.601,
        "cumulative_ms": 3.748
      },
      {
        "module": "mcp_the_force.adapters.xai.adapter",
        "self_us": 160,
        "cumulative_us": 2896,
        "self_ms": 0.16,
        "cumulative_ms": 2.896
      },
      {
        "module": "mcp_the_force.adapters.xai.definitions",
        "self_us": 2736,
        "cumulative_us": 2736,
        "self_ms": 2.736,
        "cumulative_ms": 2.736
      },
      {
        "module": "importlib_metadata._adapters",
        "self_us": 130,
        "cumulative_us": 1945,
        "self_ms": 0.13,
        "cumulative_ms": 1.945
      },
      {
        "module": "mcp_the_force.adapters.anthropic.adapter",
        "self_us": 140,
        "cumulative_us": 1765,
        "self_ms": 0.14,
        "cumulative_ms": 1.765
      },
      {
        "module": "mcp_the_force.adapters.anthropic.capabilities",
        "self_us": 1536,
        "cumulative_us": 1536,
        "self_ms": 1.536,
        "cumulative_ms": 1.536
      },
      {
        "module": "mcp_the_force.adapters.google.adapter",
        "self_us": 199,
        "cumulative_us": 1332,
        "self_ms": 0.199,
        "cumulative_ms": 1.332
      },
      {
        "module": "mcp_the_force.adapters.google.definitions",
        "self_us": 1133,
        "cumulative_us": 1133,
        "self_ms": 1.133,
        "cumulative_ms": 1.133
      },
      {
        "module": "mcp_the_force.adapters.protocol",
        "self_us": 429,
        "cumulative_us": 938,
        "self_ms": 0.429,
        "cumulative_ms": 0.938
      },
      {
        "module": "mcp_the_force.adapters.ollama.adapter",
        "self_us": 122,
        "cumulative_us": 706,
        "self_ms": 0.122,
        "cumulative_ms": 0.706
      },
      {
        "module": "mcp_the_force.adapters.ollama.blueprint_generator",
        "self_us": 113,
        "cumulative_us": 556,
        "self_ms": 0.113,
        "cumulative_ms": 0.556
      },
      {
        "module": "litellm.llms.anthropic.experimental_pass_through.adapters.handler",
        "self_us": 134,
        "cumulative_us": 555,
        "self_ms": 0.134,
        "cumulative_ms": 0.555
      },
      {
        "module": "mcp_the_force.adapters.ollama.capabilities",
        "self_us": 518,
        "cumulative_us": 518,
        "self_ms": 0.518,
        "cumulative_ms": 0.518
      },
      {
        "module": "mcp_the_force.adapters.capabilities",
        "self_us": 510,
        "cumulative_us": 510,
        "self_ms": 0.51,
        "cumulative_ms": 0.51
      },
      {
        "module": "litellm.llms.anthropic.experimental_pass_through.adapters",
        "self_us": 57,
        "cumulative_us": 421,
        "self_ms": 0.057,
        "cumulative_ms": 0.421
      },
      {
        "module": "litellm.llms.anthropic.experimental_pass_through.adapters.transformation",
        "self_us": 253,
        "cumulative_us": 365,
        "self_ms": 0.253,
        "cumulative_ms": 0.365
      },
      {
        "module": "mcp_the_force.adapters.errors",
        "self_us": 255,
        "cumulative_us": 255,
        "self_ms": 0.255,
        "cumulative_ms": 0.255
      },
      {
        "module": "mcp_the_force.adapters.ollama.overrides",
        "self_us": 235,
        "cumulative_us": 235,
        "self_ms": 0.235,
        "cumulative_ms": 0.235
      },
      {
        "module": "importlib.resources._adapters",
        "self_us": 160,
        "cumulative_us": 160,
        "self_ms": 0.16,
        "cumulative_ms": 0.16
      },
      {
        "module": "mcp_the_force.adapters.ollama.discovery",
        "self_us": 83,
        "cumulative_us": 152,
        "self_ms": 0.083,
        "cumulative_ms": 0.152
      },
      {
        "module": "mcp_the_force.adapters.params",
        "self_us": 88,
        "cumulative_us": 147,
        "self_ms": 0.088,
        "cumulative_ms": 0.147
      },
      {
        "module": "mcp_the_force.adapters.registry",
        "self_us": 133,
        "cumulative_us": 133,
        "self_ms": 0.133,
        "cumulative_ms": 0.133
      },
      {
        "module": "mcp_the_force.adapters.openai.constants",
        "self_us": 127,
        "cumulative_us": 127,
        "self_ms": 0.127,
        "cumulative_ms": 0.127
      },
      {
        "module": "mcp_the_force.adapters.openai.client",
        "self_us": 121,
        "cumulative_us": 121,
        "self_ms": 0.121,
        "cumulative_ms": 0.121
      },
      {
        "module": "litellm.llms.anthropic.experimental_pass_through.adapters.streaming_iterator",
        "self_us": 112,
        "cumulative_us": 112,
        "self_ms": 0.112,
        "cumulative_ms": 0.112
      },
      {
        "module": "mcp_the_force.adapters.anthropic.blueprints",
        "self_us": 102,
        "cumulative_us": 102,
        "self_ms": 0.102,
        "cumulative_ms": 0.102
      },
      {
        "module": "mcp_the_force.adapters.anthropic.params",
        "self_us": 90,
        "cumulative_us": 90,
        "self_ms": 0.09,
        "cumulative_ms": 0.09
      },
      {
        "module": "mcp_the_force.adapters.ollama.params",
        "self_us": 68,
        "cumulative_us": 68,
        "self_ms": 0.068,
        "cumulative_ms": 0.068
      },
      {
        "module": "mcp_the_force.adapters.param_model",
        "self_us": 59,
        "cumulative_us": 59,
        "self_ms": 0.059,
        "cumulative_ms": 0.059
      }
    ],
    "fastmcp_imports": [
      {
        "module": "fastmcp",
        "self_us": 1630,
        "cumulative_us": 164530,
        "self_ms": 1.63,
        "cumulative_ms": 164.53
      },
      {
        "module": "fastmcp.server.server",
        "self_us": 15,
        "cumulative_us": 153657,
        "self_ms": 0.015,
        "cumulative_ms": 153.657
      },
      {
        "module": "fastmcp.server",
        "self_us": 120,
        "cumulative_us": 153643,
        "self_ms": 0.12,
        "cumulative_ms": 153.643
      },
      {
        "module": "fastmcp.server.server",
        "self_us": 913,
        "cumulative_us": 152752,
        "self_ms": 0.913,
        "cumulative_ms": 152.752
      },
      {
        "module": "mcp.server.fastmcp",
        "self_us": 872,
        "cumulative_us": 32526,
        "self_ms": 0.872,
        "cumulative_ms": 32.526
      },
      {
        "module": "mcp.server.fastmcp.server",
        "self_us": 1023,
        "cumulative_us": 31655,
        "self_ms": 1.023,
        "cumulative_ms": 31.655
      },
      {
        "module": "fastmcp.server.auth.auth",
        "self_us": 17,
        "cumulative_us": 23907,
        "self_ms": 0.017,
        "cumulative_ms": 23.907
      },
      {
        "module": "fastmcp.server.auth",
        "self_us": 134,
        "cumulative_us": 23890,
        "self_ms": 0.134,
        "cumulative_ms": 23.89
      },
      {
        "module": "fastmcp.server.auth.providers.bearer",
        "self_us": 608,
        "cumulative_us": 23757,
        "self_ms": 0.608,
        "cumulative_ms": 23.757
      },
      {
        "module": "fastmcp.server.http",
        "self_us": 202,
        "cumulative_us": 6192,
        "self_ms": 0.202,
        "cumulative_ms": 6.192
      },
      {
        "module": "fastmcp.resources",
        "self_us": 81,
        "cumulative_us": 6029,
        "self_ms": 0.081,
        "cumulative_ms": 6.029
      },
      {
        "module": "fastmcp.client",
        "self_us": 96,
        "cumulative_us": 5543,
        "self_ms": 0.096,
        "cumulative_ms": 5.543
      },
      {
        "module": "fastmcp.client.client",
        "self_us": 727,
        "cumulative_us": 5447,
        "self_ms": 0.727,
        "cumulative_ms": 5.447
      },
      {
        "module": "fastmcp.server.middleware",
        "self_us": 73,
        "cumulative_us": 5032,
        "self_ms": 0.073,
        "cumulative_ms": 5.032
      },
      {
        "module": "fastmcp.server.middleware.middleware",
        "self_us": 659,
        "cumulative_us": 4959,
        "self_ms": 0.659,
        "cumulative_ms": 4.959
      },
      {
        "module": "fastmcp.tools.tool",
        "self_us": 12,
        "cumulative_us": 4301,
        "self_ms": 0.012,
        "cumulative_ms": 4.301
      },
      {
        "module": "fastmcp.tools",
        "self_us": 76,
        "cumulative_us": 4289,
        "self_ms": 0.076,
        "cumulative_ms": 4.289
      },
      {
        "module": "mcp.server.fastmcp.resources",
        "self_us": 74,
        "cumulative_us": 4180,
        "self_ms": 0.074,
        "cumulative_ms": 4.18
      },
      {
        "module": "fastmcp.settings",
        "self_us": 1823,
        "cumulative_us": 3702,
        "self_ms": 1.823,
        "cumulative_ms": 3.702
      },
      {
        "module": "mcp.server.fastmcp.resources.resource_manager",
        "self_us": 109,
        "cumulative_us": 3495,
        "self_ms": 0.109,
        "cumulative_ms": 3.495
      },
      {
        "module": "mcp.server.fastmcp.resources.templates",
        "self_us": 615,
        "cumulative_us": 3386,
        "self_ms": 0.615,
        "cumulative_ms": 3.386
      },
      {
        "module": "fastmcp.resources.types",
        "self_us": 3293,
        "cumulative_us": 3359,
        "self_ms": 3.293,
        "cumulative_ms": 3.359
      },
      {
        "module": "fastmcp.prompts",
        "self_us": 96,
        "cumulative_us": 2850,
        "self_ms": 0.096,
        "cumulative_ms": 2.85
      },
      {
        "module": "mcp.server.fastmcp.resources.types",
        "self_us": 2772,
        "cumulative_us": 2772,
        "self_ms": 2.772,
        "cumulative_ms": 2.772
      },
      {
        "module": "fastmcp.client.transports",
        "self_us": 418,
        "cumulative_us": 2745,
        "self_ms": 0.418,
        "cumulative_ms": 2.745
      },
      {
        "module": "fastmcp.prompts.prompt",
        "self_us": 1337,
        "cumulative_us": 2609,
        "self_ms": 1.337,
        "cumulative_ms": 2.609
      },
      {
        "module": "mcp.server.fastmcp.prompts",
        "self_us": 79,
        "cumulative_us": 2388,
        "self_ms": 0.079,
        "cumulative_ms": 2.388
      },
      {
        "module": "fastmcp.client.auth.bearer",
        "self_us": 10,
        "cumulative_us": 2216,
        "self_ms": 0.01,
        "cumulative_ms": 2.216
      },
      {
        "module": "fastmcp.client.auth",
        "self_us": 71,
        "cumulative_us": 2206,
        "self_ms": 0.071,
        "cumulative_ms": 2.206
      },
      {
        "module": "fastmcp.tools.tool_transform",
        "self_us": 2037,
        "cumulative_us": 2037,
        "self_ms": 2.037,
        "cumulative_ms": 2.037
      },
      {
        "module": "fastmcp.tools.tool",
        "self_us": 2034,
        "cumulative_us": 2034,
        "self_ms": 2.034,
        "cumulative_ms": 2.034
      },
      {
        "module": "fastmcp.client.auth.oauth",
        "self_us": 159,
        "cumulative_us": 2032,
        "self_ms": 0.159,
        "cumulative_ms": 2.032
      },
      {
        "module": "mcp.server.fastmcp.prompts.base",
        "self_us": 1917,
        "cumulative_us": 2023,
        "self_ms": 1.917,
        "cumulative_ms": 2.023
      },
      {
        "module": "fastmcp.mcp_config",
        "self_us": 1955,
        "cumulative_us": 1955,
        "self_ms": 1.955,
        "cumulative_ms": 1.955
      },
      {
        "module": "fastmcp.utilities.logging",
        "self_us": 136,
        "cumulative_us": 1880,
        "self_ms": 0.136,
        "cumulative_ms": 1.88
      },
      {
        "module": "mcp.server.fastmcp.tools",
        "self_us": 111,
        "cumulative_us": 1835,
        "self_ms": 0.111,
        "cumulative_ms": 1.835
      },
      {
        "module": "mcp.server.fastmcp.tools.base",
        "self_us": 715,
        "cumulative_us": 1624,
        "self_ms": 0.715,
        "cumulative_ms": 1.624
      },
      {
        "module": "fastmcp.resources.resource",
        "self_us": 1266,
        "cumulative_us": 1266,
        "self_ms": 1.266,
        "cumulative_ms": 1.266
      },
      {
        "module": "fastmcp.client.elicitation",
        "self_us": 831,
        "cumulative_us": 1216,
        "self_ms": 0.831,
        "cumulative_ms": 1.216
      },
      {
        "module": "fastmcp.resources.template",
        "self_us": 1123,
        "cumulative_us": 1123,
        "self_ms": 1.123,
        "cumulative_ms": 1.123
      },
      {
        "module": "fastmcp.utilities.components",
        "self_us": 885,
        "cumulative_us": 1102,
        "self_ms": 0.885,
        "cumulative_ms": 1.102
      },
      {
        "module": "mcp.server.fastmcp.utilities.func_metadata",
        "self_us": 823,
        "cumulative_us": 909,
        "self_ms": 0.823,
        "cumulative_ms": 0.909
      },
      {
        "module": "fastmcp.server.context",
        "self_us": 311,
        "cumulative_us": 772,
        "self_ms": 0.311,
        "cumulative_ms": 0.772
      },
      {
        "module": "fastmcp.server.auth.providers.bearer_env",
        "self_us": 624,
        "cumulative_us": 624,
        "self_ms": 0.624,
        "cumulative_ms": 0.624
      },
      {
        "module": "mcp.server.fastmcp.resources.base",
        "self_us": 612,
        "cumulative_us": 612,
        "self_ms": 0.612,
        "cumulative_ms": 0.612
      },
      {
        "module": "fastmcp.server.elicitation",
        "self_us": 461,
        "cumulative_us": 461,
        "self_ms": 0.461,
        "cumulative_ms": 0.461
      },
      {
        "module": "fastmcp.client.oauth_callback",
        "self_us": 335,
        "cumulative_us": 402,
        "self_ms": 0.335,
        "cumulative_ms": 0.402
      },
      {
        "module": "fastmcp.utilities.json_schema_type",
        "self_us": 385,
        "cumulative_us": 385,
        "self_ms": 0.385,
        "cumulative_ms": 0.385
      },
      {
        "module": "mcp.server.fastmcp.prompts.manager",
        "self_us": 114,
        "cumulative_us": 286,
        "self_ms": 0.114,
        "cumulative_ms": 0.286
      },
      {
        "module": "fastmcp.utilities.types",
        "self_us": 218,
        "cumulative_us": 218,
        "self_ms": 0.218,
        "cumulative_ms": 0.218
      },
      {
        "module": "fastmcp.resources.resource_manager",
        "self_us": 203,
        "cumulative_us": 203,
        "self_ms": 0.203,
        "cumulative_ms": 0.203
      },
      {
        "module": "mcp.server.fastmcp.utilities.logging",
        "self_us": 117,
        "cumulative_us": 173,
        "self_ms": 0.117,
        "cumulative_ms": 0.173
      },
      {
        "module": "fastmcp.prompts.prompt_manager",
        "self_us": 147,
        "cumulative_us": 147,
        "self_ms": 0.147,
        "cumulative_ms": 0.147
      },
      {
        "module": "fastmcp.tools.tool_manager",
        "self_us": 144,
        "cumulative_us": 144,
        "self_ms": 0.144,
        "cumulative_ms": 0.144
      },
      {
        "module": "fastmcp.exceptions",
        "self_us": 135,
        "cumulative_us": 135,
        "self_ms": 0.135,
        "cumulative_ms": 0.135
      },
      {
        "module": "fastmcp.server.auth.auth",
        "self_us": 132,
        "cumulative_us": 132,
        "self_ms": 0.132,
        "cumulative_ms": 0.132
      },
      {
        "module": "mcp.server.fastmcp.exceptions",
        "self_us": 121,
        "cumulative_us": 121,
        "self_ms": 0.121,
        "cumulative_ms": 0.121
      },
      {
        "module": "fastmcp.server.low_level",
        "self_us": 117,
        "cumulative_us": 117,
        "self_ms": 0.117,
        "cumulative_ms": 0.117
      },
      {
        "module": "fastmcp.utilities.cache",
        "self_us": 108,
        "cumulative_us": 108,
        "self_ms": 0.108,
        "cumulative_ms": 0.108
      },
      {
        "module": "fastmcp.client.messages",
        "self_us": 104,
        "cumulative_us": 104,
        "self_ms": 0.104,
        "cumulative_ms": 0.104
      },
      {
        "module": "fastmcp.client.auth.bearer",
        "self_us": 104,
        "cumulative_us": 104,
        "self_ms": 0.104,
        "cumulative_ms": 0.104
      },
      {
        "module": "mcp.server.fastmcp.tools.tool_manager",
        "self_us": 101,
        "cumulative_us": 101,
        "self_ms": 0.101,
        "cumulative_ms": 0.101
      },
      {
        "module": "fastmcp.utilities.json_schema",
        "self_us": 92,
        "cumulative_us": 92,
        "self_ms": 0.092,
        "cumulative_ms": 0.092
      },
      {
        "module": "fastmcp.utilities.cli",
        "self_us": 92,
        "cumulative_us": 92,
        "self_ms": 0.092,
        "cumulative_ms": 0.092
      },
      {
        "module": "fastmcp.server.auth.providers",
        "self_us": 89,
        "cumulative_us": 89,
        "self_ms": 0.089,
        "cumulative_ms": 0.089
      },
      {
        "module": "mcp.server.fastmcp.utilities.types",
        "self_us": 87,
        "cumulative_us": 87,
        "self_ms": 0.087,
        "cumulative_ms": 0.087
      },
      {
        "module": "fastmcp.client.logging",
        "self_us": 83,
        "cumulative_us": 83,
        "self_ms": 0.083,
        "cumulative_ms": 0.083
      },
      {
        "module": "fastmcp.server.dependencies",
        "self_us": 79,
        "cumulative_us": 79,
        "self_ms": 0.079,
        "cumulative_ms": 0.079
      },
      {
        "module": "fastmcp.utilities.exceptions",
        "self_us": 79,
        "cumulative_us": 79,
        "self_ms": 0.079,
        "cumulative_ms": 0.079
      },
      {
        "module": "fastmcp.client.roots",
        "self_us": 72,
        "cumulative_us": 72,
        "self_ms": 0.072,
        "cumulative_ms": 0.072
      },
      {
        "module": "fastmcp.utilities.http",
        "self_us": 67,
        "cumulative_us": 67,
        "self_ms": 0.067,
        "cumulative_ms": 0.067
      },
      {
        "module": "fastmcp.client.progress",
        "self_us": 62,
        "cumulative_us": 62,
        "self_ms": 0.062,
        "cumulative_ms": 0.062
      },
      {
        "module": "fastmcp.client.sampling",
        "self_us": 60,
        "cumulative_us": 60,
        "self_ms": 0.06,
        "cumulative_ms": 0.06
      },
      {
        "module": "fastmcp.utilities",
        "self_us": 58,
        "cumulative_us": 58,
        "self_ms": 0.058,
        "cumulative_ms": 0.058
      },
      {
        "module": "mcp.server.fastmcp.utilities",
        "self_us": 56,
        "cumulative_us": 56,
        "self_ms": 0.056,
        "cumulative_ms": 0.056
      }
    ],
    "dependency_imports": [
      {
        "module": "litellm.llms.custom_httpx.http_handler",
        "self_us": 505,
        "cumulative_us": 313145,
        "self_ms": 0.505,
        "cumulative_ms": 313.145
      },
      {
        "module": "openai._models",
        "self_us": 8,
        "cumulative_us": 149259,
        "self_ms": 0.008,
        "cumulative_ms": 149.259
      },
      {
        "module": "openai",
        "self_us": 367,
        "cumulative_us": 149252,
        "self_ms": 0.367,
        "cumulative_ms": 149.252
      },
      {
        "module": "openai.types",
        "self_us": 346,
        "cumulative_us": 122185,
        "self_ms": 0.346,
        "cumulative_ms": 122.185
      },
      {
        "module": "openai.types.batch",
        "self_us": 612,
        "cumulative_us": 62534,
        "self_ms": 0.612,
        "cumulative_ms": 62.534
      },
      {
        "module": "openai._models",
        "self_us": 2552,
        "cumulative_us": 59162,
        "self_ms": 2.552,
        "cumulative_ms": 59.162
      },
      {
        "module": "httpx",
        "self_us": 159,
        "cumulative_us": 44748,
        "self_ms": 0.159,
        "cumulative_ms": 44.748
      },
      {
        "module": "openai.types.eval_create_params",
        "self_us": 394,
        "cumulative_us": 42247,
        "self_ms": 0.394,
        "cumulative_ms": 42.247
      },
      {
        "module": "openai.types.graders.python_grader_param",
        "self_us": 9,
        "cumulative_us": 40885,
        "self_ms": 0.009,
        "cumulative_ms": 40.885
      },
      {
        "module": "openai.types.graders",
        "self_us": 67,
        "cumulative_us": 40877,
        "self_ms": 0.067,
        "cumulative_ms": 40.877
      },
      {
        "module": "openai.types.graders.multi_grader",
        "self_us": 198,
        "cumulative_us": 40043,
        "self_ms": 0.198,
        "cumulative_ms": 40.043
      },
      {
        "module": "openai.types.graders.label_model_grader",
        "self_us": 487,
        "cumulative_us": 38839,
        "self_ms": 0.487,
        "cumulative_ms": 38.839
      },
      {
        "module": "openai.types.responses.response_input_text",
        "self_us": 13,
        "cumulative_us": 38352,
        "self_ms": 0.013,
        "cumulative_ms": 38.352
      },
      {
        "module": "openai.types.responses",
        "self_us": 253,
        "cumulative_us": 38340,
        "self_ms": 0.253,
        "cumulative_ms": 38.34
      },
      {
        "module": "httpx._main",
        "self_us": 281,
        "cumulative_us": 32490,
        "self_ms": 0.281,
        "cumulative_ms": 32.49
      },
      {
        "module": "litellm.types.llms.openai",
        "self_us": 22487,
        "cumulative_us": 28785,
        "self_ms": 22.487,
        "cumulative_ms": 28.785
      },
      {
        "module": "openai._utils",
        "self_us": 130,
        "cumulative_us": 26401,
        "self_ms": 0.13,
        "cumulative_ms": 26.401
      },
      {
        "module": "mcp_the_force.adapters.openai.adapter",
        "self_us": 145,
        "cumulative_us": 22043,
        "self_ms": 0.145,
        "cumulative_ms": 22.043
      },
      {
        "module": "openai.lib.streaming",
        "self_us": 67,
        "cumulative_us": 20125,
        "self_ms": 0.067,
        "cumulative_ms": 20.125
      },
      {
        "module": "openai.lib.streaming._assistants",
        "self_us": 342,
        "cumulative_us": 20058,
        "self_ms": 0.342,
        "cumulative_ms": 20.058
      },
      {
        "module": "openai.types.beta",
        "self_us": 115,
        "cumulative_us": 19716,
        "self_ms": 0.115,
        "cumulative_ms": 19.716
      },
      {
        "module": "mcp_the_force.adapters.openai.flow",
        "self_us": 465,
        "cumulative_us": 18151,
        "self_ms": 0.465,
        "cumulative_ms": 18.151
      },
      {
        "module": "pydantic.fields",
        "self_us": 932,
        "cumulative_us": 17066,
        "self_ms": 0.932,
        "cumulative_ms": 17.066
      },
      {
        "module": "openai._utils._logs",
        "self_us": 123,
        "cumulative_us": 16173,
        "self_ms": 0.123,
        "cumulative_ms": 16.173
      },
      {
        "module": "openai._utils._utils",
        "self_us": 157,
        "cumulative_us": 16051,
        "self_ms": 0.157,
        "cumulative_ms": 16.051
      },
      {
        "module": "openai._compat",
        "self_us": 7398,
        "cumulative_us": 15556,
        "self_ms": 7.398,
        "cumulative_ms": 15.556
      },
      {
        "module": "openai.types.beta.thread_create_params",
        "self_us": 313,
        "cumulative_us": 14154,
        "self_ms": 0.313,
        "cumulative_ms": 14.154
      },
      {
        "module": "openai.types.beta.threads.message_content_part_param",
        "self_us": 10,
        "cumulative_us": 13842,
        "self_ms": 0.01,
        "cumulative_ms": 13.842
      },
      {
        "module": "openai.types.beta.threads",
        "self_us": 277,
        "cumulative_us": 13832,
        "self_ms": 0.277,
        "cumulative_ms": 13.832
      },
      {
        "module": "httpx._api",
        "self_us": 77,
        "cumulative_us": 12027,
        "self_ms": 0.077,
        "cumulative_ms": 12.027
      },
      {
        "module": "httpx._client",
        "self_us": 335,
        "cumulative_us": 11950,
        "self_ms": 0.335,
        "cumulative_ms": 11.95
      },
      {
        "module": "httpx._auth",
        "self_us": 244,
        "cumulative_us": 10488,
        "self_ms": 0.244,
        "cumulative_ms": 10.488
      },
      {
        "module": "pydantic.types",
        "self_us": 3165,
        "cumulative_us": 10390,
        "self_ms": 3.165,
        "cumulative_ms": 10.39
      },
      {
        "module": "openai.types.responses.response",
        "self_us": 786,
        "cumulative_us": 10202,
        "self_ms": 0.786,
        "cumulative_ms": 10.202
      },
      {
        "module": "openai._utils._sync",
        "self_us": 97,
        "cumulative_us": 9598,
        "self_ms": 0.097,
        "cumulative_ms": 9.598
      },
      {
        "module": "openai.types.responses.response_stream_event",
        "self_us": 304,
        "cumulative_us": 8614,
        "self_ms": 0.304,
        "cumulative_ms": 8.614
      },
      {
        "module": "pydantic",
        "self_us": 159,
        "cumulative_us": 8565,
        "self_ms": 0.159,
        "cumulative_ms": 8.565
      },
      {
        "module": "pydantic.v1.typing",
        "self_us": 12,
        "cumulative_us": 8088,
        "self_ms": 0.012,
        "cumulative_ms": 8.088
      },
      {
        "module": "pydantic.v1",
        "self_us": 128,
        "cumulative_us": 8077,
        "self_ms": 0.128,
        "cumulative_ms": 8.077
      },
      {
        "module": "openai.types.responses.tool_param",
        "self_us": 499,
        "cumulative_us": 8029,
        "self_ms": 0.499,
        "cumulative_ms": 8.029
      },
      {
        "module": "tiktoken",
        "self_us": 108,
        "cumulative_us": 7645,
        "self_ms": 0.108,
        "cumulative_ms": 7.645
      },
      {
        "module": "pydantic.v1.dataclasses",
        "self_us": 260,
        "cumulative_us": 7041,
        "self_ms": 0.26,
        "cumulative_ms": 7.041
      },
      {
        "module": "tiktoken.core",
        "self_us": 179,
        "cumulative_us": 7039,
        "self_ms": 0.179,
        "cumulative_ms": 7.039
      },
      {
        "module": "openai.types.chat.chat_completion_tool_param",
        "self_us": 17,
        "cumulative_us": 6990,
        "self_ms": 0.017,
        "cumulative_ms": 6.99
      },
      {
        "module": "openai.types.chat",
        "self_us": 156,
        "cumulative_us": 6973,
        "self_ms": 0.156,
        "cumulative_ms": 6.973
      },
      {
        "module": "openai.types.responses.response_input_item",
        "self_us": 1662,
        "cumulative_us": 6263,
        "self_ms": 1.662,
        "cumulative_ms": 6.263
      },
      {
        "module": "httpx._models",
        "self_us": 334,
        "cumulative_us": 6255,
        "self_ms": 0.334,
        "cumulative_ms": 6.255
      },
      {
        "module": "pydantic._migration",
        "self_us": 124,
        "cumulative_us": 6192,
        "self_ms": 0.124,
        "cumulative_ms": 6.192
      },
      {
        "module": "pydantic.version",
        "self_us": 73,
        "cumulative_us": 6068,
        "self_ms": 0.073,
        "cumulative_ms": 6.068
      },
      {
        "module": "pydantic_core",
        "self_us": 366,
        "cumulative_us": 5995,
        "self_ms": 0.366,
        "cumulative_ms": 5.995
      },
      {
        "module": "openai.types.beta.threads.run_create_params",
        "self_us": 347,
        "cumulative_us": 5245,
        "self_ms": 0.347,
        "cumulative_ms": 5.245
      },
      {
        "module": "litellm.llms.base_llm.google_genai.transformation",
        "self_us": 134,
        "cumulative_us": 5098,
        "self_ms": 0.134,
        "cumulative_ms": 5.098
      },
      {
        "module": "mcp_the_force.adapters.openai.models",
        "self_us": 5080,
        "cumulative_us": 5080,
        "self_ms": 5.08,
        "cumulative_ms": 5.08
      },
      {
        "module": "litellm.llms.base_llm.google_genai",
        "self_us": 45,
        "cumulative_us": 4964,
        "self_ms": 0.045,
        "cumulative_ms": 4.964
      },
      {
        "module": "openai._client",
        "self_us": 372,
        "cumulative_us": 4931,
        "self_ms": 0.372,
        "cumulative_ms": 4.931
      },
      {
        "module": "pydantic_core.core_schema",
        "self_us": 4698,
        "cumulative_us": 4698,
        "self_ms": 4.698,
        "cumulative_ms": 4.698
      },
      {
        "module": "openai._types",
        "self_us": 1207,
        "cumulative_us": 4434,
        "self_ms": 1.207,
        "cumulative_ms": 4.434
      },
      {
        "module": "openai.types.beta.threads.runs.run_step_include",
        "self_us": 13,
        "cumulative_us": 4223,
        "self_ms": 0.013,
        "cumulative_ms": 4.223
      },
      {
        "module": "openai.types.beta.threads.runs",
        "self_us": 156,
        "cumulative_us": 4211,
        "self_ms": 0.156,
        "cumulative_ms": 4.211
      },
      {
        "module": "pydantic.json_schema",
        "self_us": 1229,
        "cumulative_us": 4018,
        "self_ms": 1.229,
        "cumulative_ms": 4.018
      },
      {
        "module": "openai._base_client",
        "self_us": 1812,
        "cumulative_us": 3923,
        "self_ms": 1.812,
        "cumulative_ms": 3.923
      },
      {
        "module": "mcp_the_force.adapters.openai.definitions",
        "self_us": 3601,
        "cumulative_us": 3748,
        "self_ms": 3.601,
        "cumulative_ms": 3.748
      },
      {
        "module": "openai.types.audio.transcription_create_params",
        "self_us": 13,
        "cumulative_us": 3737,
        "self_ms": 0.013,
        "cumulative_ms": 3.737
      },
      {
        "module": "openai.types.audio",
        "self_us": 157,
        "cumulative_us": 3724,
        "self_ms": 0.157,
        "cumulative_ms": 3.724
      },
      {
        "module": "openai.types.fine_tuning.fine_tuning_job",
        "self_us": 11,
        "cumulative_us": 3511,
        "self_ms": 0.011,
        "cumulative_ms": 3.511
      },
      {
        "module": "openai.types.fine_tuning",
        "self_us": 111,
        "cumulative_us": 3500,
        "self_ms": 0.111,
        "cumulative_ms": 3.5
      },
      {
        "module": "pydantic_settings",
        "self_us": 121,
        "cumulative_us": 3387,
        "self_ms": 0.121,
        "cumulative_ms": 3.387
      },
      {
        "module": "litellm.llms.base_llm.anthropic_messages.transformation",
        "self_us": 155,
        "cumulative_us": 3293,
        "self_ms": 0.155,
        "cumulative_ms": 3.293
      },
      {
        "module": "pydantic._internal._model_construction",
        "self_us": 412,
        "cumulative_us": 3228,
        "self_ms": 0.412,
        "cumulative_ms": 3.228
      },
      {
        "module": "pydantic_settings.main",
        "self_us": 514,
        "cumulative_us": 3115,
        "self_ms": 0.514,
        "cumulative_ms": 3.115
      },
      {
        "module": "pydantic._internal._fields",
        "self_us": 347,
        "cumulative_us": 3113,
        "self_ms": 0.347,
        "cumulative_ms": 3.113
      },
      {
        "module": "litellm.llms.openai_like.chat.handler",
        "self_us": 186,
        "cumulative_us": 3072,
        "self_ms": 0.186,
        "cumulative_ms": 3.072
      },
      {
        "module": "litellm.types.llms.anthropic_messages.anthropic_response",
        "self_us": 292,
        "cumulative_us": 3070,
        "self_ms": 0.292,
        "cumulative_ms": 3.07
      },
      {
        "module": "pydantic.v1.error_wrappers",
        "self_us": 191,
        "cumulative_us": 2997,
        "self_ms": 0.191,
        "cumulative_ms": 2.997
      },
      {
        "module": "pydantic.v1.json",
        "self_us": 114,
        "cumulative_us": 2807,
        "self_ms": 0.114,
        "cumulative_ms": 2.807
      },
      {
        "module": "openai.types.responses.response_input_param",
        "self_us": 680,
        "cumulative_us": 2807,
        "self_ms": 0.68,
        "cumulative_ms": 2.807
      },
      {
        "module": "litellm.types.llms.anthropic",
        "self_us": 2265,
        "cumulative_us": 2746,
        "self_ms": 2.265,
        "cumulative_ms": 2.746
      },
      {
        "module": "pydantic._internal._validators",
        "self_us": 196,
        "cumulative_us": 2669,
        "self_ms": 0.196,
        "cumulative_ms": 2.669
      },
      {
        "module": "pydantic._internal._generate_schema",
        "self_us": 724,
        "cumulative_us": 2662,
        "self_ms": 0.724,
        "cumulative_ms": 2.662
      },
      {
        "module": "openai.types.chat.completion_create_params",
        "self_us": 486,
        "cumulative_us": 2450,
        "self_ms": 0.486,
        "cumulative_ms": 2.45
      },
      {
        "module": "openai.types.responses.tool",
        "self_us": 1453,
        "cumulative_us": 2431,
        "self_ms": 1.453,
        "cumulative_ms": 2.431
      },
      {
        "module": "openai.types.shared.metadata",
        "self_us": 12,
        "cumulative_us": 2419,
        "self_ms": 0.012,
        "cumulative_ms": 2.419
      },
      {
        "module": "openai.types.shared",
        "self_us": 103,
        "cumulative_us": 2408,
        "self_ms": 0.103,
        "cumulative_ms": 2.408
      },
      {
        "module": "pydantic_settings.sources",
        "self_us": 72,
        "cumulative_us": 2374,
        "self_ms": 0.072,
        "cumulative_ms": 2.374
      },
      {
        "module": "pydantic.errors",
        "self_us": 257,
        "cumulative_us": 2215,
        "self_ms": 0.257,
        "cumulative_ms": 2.215
      },
      {
        "module": "openai.types.beta.threads.run",
        "self_us": 1450,
        "cumulative_us": 2208,
        "self_ms": 1.45,
        "cumulative_ms": 2.208
      },
      {
        "module": "httpx._urls",
        "self_us": 188,
        "cumulative_us": 2148,
        "self_ms": 0.188,
        "cumulative_ms": 2.148
      },
      {
        "module": "openai.types.completion_create_params",
        "self_us": 2148,
        "cumulative_us": 2148,
        "self_ms": 2.148,
        "cumulative_ms": 2.148
      },
      {
        "module": "openai.types.beta.threads.runs.run_step",
        "self_us": 505,
        "cumulative_us": 2024,
        "self_ms": 0.505,
        "cumulative_ms": 2.024
      },
      {
        "module": "openai.types.responses.response_item",
        "self_us": 1191,
        "cumulative_us": 2005,
        "self_ms": 1.191,
        "cumulative_ms": 2.005
      },
      {
        "module": "pydantic.v1.class_validators",
        "self_us": 230,
        "cumulative_us": 1974,
        "self_ms": 0.23,
        "cumulative_ms": 1.974
      },
      {
        "module": "litellm.llms.openai.openai",
        "self_us": 1814,
        "cumulative_us": 1924,
        "self_ms": 1.814,
        "cumulative_ms": 1.924
      },
      {
        "module": "openai.types.beta.threads.message",
        "self_us": 804,
        "cumulative_us": 1825,
        "self_ms": 0.804,
        "cumulative_ms": 1.825
      },
      {
        "module": "openai.types.beta.assistant_stream_event",
        "self_us": 1824,
        "cumulative_us": 1824,
        "self_ms": 1.824,
        "cumulative_ms": 1.824
      },
      {
        "module": "mcp_the_force.adapters.anthropic.adapter",
        "self_us": 140,
        "cumulative_us": 1765,
        "self_ms": 0.14,
        "cumulative_ms": 1.765
      },
      {
        "module": "pydantic._internal._decorators",
        "self_us": 1665,
        "cumulative_us": 1665,
        "self_ms": 1.665,
        "cumulative_ms": 1.665
      },
      {
        "module": "openai.types.beta.threads.runs.run_step_delta",
        "self_us": 161,
        "cumulative_us": 1655,
        "self_ms": 0.161,
        "cumulative_ms": 1.655
      },
      {
        "module": "openai.types.fine_tuning.fine_tuning_job",
        "self_us": 649,
        "cumulative_us": 1639,
        "self_ms": 0.649,
        "cumulative_ms": 1.639
      },
      {
        "module": "openai.types.chat.chat_completion",
        "self_us": 535,
        "cumulative_us": 1618,
        "self_ms": 0.535,
        "cumulative_ms": 1.618
      },
      {
        "module": "mcp_the_force.adapters.anthropic.capabilities",
        "self_us": 1536,
        "cumulative_us": 1536,
        "self_ms": 1.536,
        "cumulative_ms": 1.536
      },
      {
        "module": "pydantic._internal._generics",
        "self_us": 283,
        "cumulative_us": 1428,
        "self_ms": 0.283,
        "cumulative_ms": 1.428
      },
      {
        "module": "pydantic_settings.sources.providers.aws",
        "self_us": 11,
        "cumulative_us": 1418,
        "self_ms": 0.011,
        "cumulative_ms": 1.418
      },
      {
        "module": "pydantic_settings.sources.providers",
        "self_us": 92,
        "cumulative_us": 1407,
        "self_ms": 0.092,
        "cumulative_ms": 1.407
      },
      {
        "module": "pydantic.v1.networks",
        "self_us": 489,
        "cumulative_us": 1405,
        "self_ms": 0.489,
        "cumulative_ms": 1.405
      },
      {
        "module": "litellm.llms.anthropic.cost_calculation",
        "self_us": 109,
        "cumulative_us": 1386,
        "self_ms": 0.109,
        "cumulative_ms": 1.386
      },
      {
        "module": "openai.types.chat.chat_completion_message_param",
        "self_us": 82,
        "cumulative_us": 1384,
        "self_ms": 0.082,
        "cumulative_ms": 1.384
      },
      {
        "module": "openai.types.beta.threads.message_delta",
        "self_us": 276,
        "cumulative_us": 1369,
        "self_ms": 0.276,
        "cumulative_ms": 1.369
      },
      {
        "module": "litellm.llms.vertex_ai.gemini.vertex_and_google_ai_studio_gemini",
        "self_us": 492,
        "cumulative_us": 1361,
        "self_ms": 0.492,
        "cumulative_ms": 1.361
      },
      {
        "module": "openai.pagination",
        "self_us": 1354,
        "cumulative_us": 1354,
        "self_ms": 1.354,
        "cumulative_ms": 1.354
      },
      {
        "module": "pydantic.functional_validators",
        "self_us": 1333,
        "cumulative_us": 1333,
        "self_ms": 1.333,
        "cumulative_ms": 1.333
      },
      {
        "module": "mcp_the_force.adapters.google.adapter",
        "self_us": 199,
        "cumulative_us": 1332,
        "self_ms": 0.199,
        "cumulative_ms": 1.332
      },
      {
        "module": "openai.types.beta.threads.runs.tool_calls_step_details",
        "self_us": 137,
        "cumulative_us": 1331,
        "self_ms": 0.137,
        "cumulative_ms": 1.331
      },
      {
        "module": "openai.types.beta.assistant",
        "self_us": 511,
        "cumulative_us": 1314,
        "self_ms": 0.511,
        "cumulative_ms": 1.314
      },
      {
        "module": "openai.types.beta.threads.runs.tool_call_delta_object",
        "self_us": 142,
        "cumulative_us": 1297,
        "self_ms": 0.142,
        "cumulative_ms": 1.297
      },
      {
        "module": "openai.types.responses.response_computer_tool_call",
        "self_us": 1278,
        "cumulative_us": 1278,
        "self_ms": 1.278,
        "cumulative_ms": 1.278
      },
      {
        "module": "litellm.llms.anthropic",
        "self_us": 91,
        "cumulative_us": 1277,
        "self_ms": 0.091,
        "cumulative_ms": 1.277
      },
      {
        "module": "pydantic._internal._config",
        "self_us": 190,
        "cumulative_us": 1206,
        "self_ms": 0.19,
        "cumulative_ms": 1.206
      },
      {
        "module": "openai.types.beta.threads.runs.tool_call",
        "self_us": 74,
        "cumulative_us": 1195,
        "self_ms": 0.074,
        "cumulative_ms": 1.195
      },
      {
        "module": "httpx._content",
        "self_us": 147,
        "cumulative_us": 1191,
        "self_ms": 0.147,
        "cumulative_ms": 1.191
      },
      {
        "module": "litellm.types.proxy.guardrails.guardrail_hooks.openai.openai_moderation",
        "self_us": 650,
        "cumulative_us": 1179,
        "self_ms": 0.65,
        "cumulative_ms": 1.179
      },
      {
        "module": "openai.types.beta.threads.runs.tool_call_delta",
        "self_us": 72,
        "cumulative_us": 1156,
        "self_ms": 0.072,
        "cumulative_ms": 1.156
      },
      {
        "module": "openai.types.responses.response_output_message",
        "self_us": 211,
        "cumulative_us": 1150,
        "self_ms": 0.211,
        "cumulative_ms": 1.15
      },
      {
        "module": "mcp_the_force.adapters.google.definitions",
        "self_us": 1133,
        "cumulative_us": 1133,
        "self_ms": 1.133,
        "cumulative_ms": 1.133
      },
      {
        "module": "openai.types.beta.threads.message_content_delta",
        "self_us": 143,
        "cumulative_us": 1093,
        "self_ms": 0.143,
        "cumulative_ms": 1.093
      },
      {
        "module": "pydantic.v1.errors",
        "self_us": 849,
        "cumulative_us": 1089,
        "self_ms": 0.849,
        "cumulative_ms": 1.089
      },
      {
        "module": "openai.types.moderation",
        "self_us": 1077,
        "cumulative_us": 1077,
        "self_ms": 1.077,
        "cumulative_ms": 1.077
      },
      {
        "module": "pydantic.v1.main",
        "self_us": 573,
        "cumulative_us": 1064,
        "self_ms": 0.573,
        "cumulative_ms": 1.064
      },
      {
        "module": "httpx._multipart",
        "self_us": 219,
        "cumulative_us": 1044,
        "self_ms": 0.219,
        "cumulative_ms": 1.044
      },
      {
        "module": "pydantic.v1.types",
        "self_us": 1035,
        "cumulative_us": 1035,
        "self_ms": 1.035,
        "cumulative_ms": 1.035
      },
      {
        "module": "openai.types.beta.threads.message_content",
        "self_us": 115,
        "cumulative_us": 1021,
        "self_ms": 0.115,
        "cumulative_ms": 1.021
      },
      {
        "module": "openai.types.responses.parsed_response",
        "self_us": 1017,
        "cumulative_us": 1017,
        "self_ms": 1.017,
        "cumulative_ms": 1.017
      },
      {
        "module": "litellm.llms.anthropic.chat.transformation",
        "self_us": 9,
        "cumulative_us": 1010,
        "self_ms": 0.009,
        "cumulative_ms": 1.01
      },
      {
        "module": "openai.types.eval_list_response",
        "self_us": 664,
        "cumulative_us": 1009,
        "self_ms": 0.664,
        "cumulative_ms": 1.009
      },
      {
        "module": "litellm.llms.anthropic.chat",
        "self_us": 57,
        "cumulative_us": 1002,
        "self_ms": 0.057,
        "cumulative_ms": 1.002
      },
      {
        "module": "httpx._transports.base",
        "self_us": 12,
        "cumulative_us": 1000,
        "self_ms": 0.012,
        "cumulative_ms": 1.0
      },
      {
        "module": "httpx._transports",
        "self_us": 76,
        "cumulative_us": 989,
        "self_ms": 0.076,
        "cumulative_ms": 0.989
      },
      {
        "module": "openai.types.beta.threads.text_delta",
        "self_us": 227,
        "cumulative_us": 982,
        "self_ms": 0.227,
        "cumulative_ms": 0.982
      },
      {
        "module": "litellm.llms.custom_httpx.llm_http_handler",
        "self_us": 684,
        "cumulative_us": 981,
        "self_ms": 0.684,
        "cumulative_ms": 0.981
      },
      {
        "module": "litellm.llms.anthropic.experimental_pass_through.messages.handler",
        "self_us": 114,
        "cumulative_us": 981,
        "self_ms": 0.114,
        "cumulative_ms": 0.981
      },
      {
        "module": "openai.types.shared_params.metadata",
        "self_us": 10,
        "cumulative_us": 969,
        "self_ms": 0.01,
        "cumulative_ms": 0.969
      },
      {
        "module": "openai.types.shared_params",
        "self_us": 97,
        "cumulative_us": 959,
        "self_ms": 0.097,
        "cumulative_ms": 0.959
      },
      {
        "module": "openai.types.eval_retrieve_response",
        "self_us": 954,
        "cumulative_us": 954,
        "self_ms": 0.954,
        "cumulative_ms": 0.954
      },
      {
        "module": "litellm.llms.anthropic.chat.handler",
        "self_us": 311,
        "cumulative_us": 945,
        "self_ms": 0.311,
        "cumulative_ms": 0.945
      },
      {
        "module": "pydantic_core._pydantic_core",
        "self_us": 932,
        "cumulative_us": 932,
        "self_ms": 0.932,
        "cumulative_ms": 0.932
      },
      {
        "module": "openai.types.chat.chat_completion_chunk",
        "self_us": 931,
        "cumulative_us": 931,
        "self_ms": 0.931,
        "cumulative_ms": 0.931
      },
      {
        "module": "pydantic.v1.validators",
        "self_us": 269,
        "cumulative_us": 916,
        "self_ms": 0.269,
        "cumulative_ms": 0.916
      },
      {
        "module": "openai.types.responses.response_output_item",
        "self_us": 900,
        "cumulative_us": 900,
        "self_ms": 0.9,
        "cumulative_ms": 0.9
      },
      {
        "module": "mcp_the_force.vectorstores.openai",
        "self_us": 58,
        "cumulative_us": 893,
        "self_ms": 0.058,
        "cumulative_ms": 0.893
      },
      {
        "module": "openai.types.chat.parsed_chat_completion",
        "self_us": 645,
        "cumulative_us": 888,
        "self_ms": 0.645,
        "cumulative_ms": 0.888
      },
      {
        "module": "pydantic_settings.sources.base",
        "self_us": 210,
        "cumulative_us": 885,
        "self_ms": 0.21,
        "cumulative_ms": 0.885
      },
      {
        "module": "openai.types.completion",
        "self_us": 190,
        "cumulative_us": 844,
        "self_ms": 0.19,
        "cumulative_ms": 0.844
      },
      {
        "module": "openai.types.audio.transcription_stream_event",
        "self_us": 81,
        "cumulative_us": 839,
        "self_ms": 0.081,
        "cumulative_ms": 0.839
      },
      {
        "module": "mcp_the_force.vectorstores.openai.openai_vectorstore",
        "self_us": 527,
        "cumulative_us": 835,
        "self_ms": 0.527,
        "cumulative_ms": 0.835
      },
      {
        "module": "openai.types.chat.chat_completion_message",
        "self_us": 466,
        "cumulative_us": 819,
        "self_ms": 0.466,
        "cumulative_ms": 0.819
      },
      {
        "module": "openai.types.beta.threads.text",
        "self_us": 194,
        "cumulative_us": 806,
        "self_ms": 0.194,
        "cumulative_ms": 0.806
      },
      {
        "module": "openai.types.image_gen_stream_event",
        "self_us": 113,
        "cumulative_us": 800,
        "self_ms": 0.113,
        "cumulative_ms": 0.8
      },
      {
        "module": "openai.types.file_chunking_strategy",
        "self_us": 242,
        "cumulative_us": 785,
        "self_ms": 0.242,
        "cumulative_ms": 0.785
      },
      {
        "module": "openai.types.responses.response_output_text",
        "self_us": 783,
        "cumulative_us": 783,
        "self_ms": 0.783,
        "cumulative_ms": 0.783
      },
      {
        "module": "openai.types.graders.multi_grader_param",
        "self_us": 119,
        "cumulative_us": 768,
        "self_ms": 0.119,
        "cumulative_ms": 0.768
      },
      {
        "module": "openai.types.beta.threads.annotation_delta",
        "self_us": 107,
        "cumulative_us": 756,
        "self_ms": 0.107,
        "cumulative_ms": 0.756
      },
      {
        "module": "tiktoken._tiktoken",
        "self_us": 754,
        "cumulative_us": 754,
        "self_ms": 0.754,
        "cumulative_ms": 0.754
      },
      {
        "module": "openai.types.eval_create_response",
        "self_us": 732,
        "cumulative_us": 732,
        "self_ms": 0.732,
        "cumulative_ms": 0.732
      },
      {
        "module": "openai.types.responses.response_prompt",
        "self_us": 202,
        "cumulative_us": 726,
        "self_ms": 0.202,
        "cumulative_ms": 0.726
      },
      {
        "module": "openai.types.beta.assistant_tool",
        "self_us": 84,
        "cumulative_us": 726,
        "self_ms": 0.084,
        "cumulative_ms": 0.726
      },
      {
        "module": "httpx._urlparse",
        "self_us": 711,
        "cumulative_us": 711,
        "self_ms": 0.711,
        "cumulative_ms": 0.711
      },
      {
        "module": "openai.types.responses.response_input_item_param",
        "self_us": 700,
        "cumulative_us": 700,
        "self_ms": 0.7,
        "cumulative_ms": 0.7
      },
      {
        "module": "openai.types.image_edit_stream_event",
        "self_us": 114,
        "cumulative_us": 698,
        "self_ms": 0.114,
        "cumulative_ms": 0.698
      },
      {
        "module": "pydantic._internal._mock_val_ser",
        "self_us": 226,
        "cumulative_us": 672,
        "self_ms": 0.226,
        "cumulative_ms": 0.672
      },
      {
        "module": "pydantic._internal._utils",
        "self_us": 665,
        "cumulative_us": 665,
        "self_ms": 0.665,
        "cumulative_ms": 0.665
      },
      {
        "module": "openai.types.audio.transcription",
        "self_us": 663,
        "cumulative_us": 663,
        "self_ms": 0.663,
        "cumulative_ms": 0.663
      },
      {
        "module": "litellm.llms.bedrock.messages.invoke_transformations.anthropic_claude3_transformation",
        "self_us": 165,
        "cumulative_us": 663,
        "self_ms": 0.165,
        "cumulative_ms": 0.663
      },
      {
        "module": "pydantic.v1.utils",
        "self_us": 544,
        "cumulative_us": 656,
        "self_ms": 0.544,
        "cumulative_ms": 0.656
      },
      {
        "module": "openai.types.responses.response_create_params",
        "self_us": 290,
        "cumulative_us": 655,
        "self_ms": 0.29,
        "cumulative_ms": 0.655
      },
      {
        "module": "pydantic.v1.datetime_parse",
        "self_us": 648,
        "cumulative_us": 648,
        "self_ms": 0.648,
        "cumulative_ms": 0.648
      },
      {
        "module": "openai._module_client",
        "self_us": 637,
        "cumulative_us": 637,
        "self_ms": 0.637,
        "cumulative_ms": 0.637
      },
      {
        "module": "openai.types.eval_update_response",
        "self_us": 632,
        "cumulative_us": 632,
        "self_ms": 0.632,
        "cumulative_ms": 0.632
      },
      {
        "module": "openai.types.fine_tuning.job_create_params",
        "self_us": 269,
        "cumulative_us": 627,
        "self_ms": 0.269,
        "cumulative_ms": 0.627
      },
      {
        "module": "openai.types.beta.threads.runs.code_interpreter_tool_call_delta",
        "self_us": 278,
        "cumulative_us": 617,
        "self_ms": 0.278,
        "cumulative_ms": 0.617
      },
      {
        "module": "openai.types.beta.threads.annotation",
        "self_us": 103,
        "cumulative_us": 612,
        "self_ms": 0.103,
        "cumulative_ms": 0.612
      },
      {
        "module": "pydantic._internal._repr",
        "self_us": 162,
        "cumulative_us": 592,
        "self_ms": 0.162,
        "cumulative_ms": 0.592
      },
      {
        "module": "litellm.llms.anthropic.experimental_pass_through.adapters.handler",
        "self_us": 134,
        "cumulative_us": 555,
        "self_ms": 0.134,
        "cumulative_ms": 0.555
      },
      {
        "module": "pydantic.v1.env_settings",
        "self_us": 537,
        "cumulative_us": 537,
        "self_ms": 0.537,
        "cumulative_ms": 0.537
      },
      {
        "module": "pydantic.aliases",
        "self_us": 483,
        "cumulative_us": 533,
        "self_ms": 0.483,
        "cumulative_ms": 0.533
      },
      {
        "module": "openai.types.audio.translation_verbose",
        "self_us": 180,
        "cumulative_us": 528,
        "self_ms": 0.18,
        "cumulative_ms": 0.528
      },
      {
        "module": "openai.types.fine_tuning.dpo_method",
        "self_us": 174,
        "cumulative_us": 521,
        "self_ms": 0.174,
        "cumulative_ms": 0.521
      },
      {
        "module": "httpx._types",
        "self_us": 509,
        "cumulative_us": 509,
        "self_ms": 0.509,
        "cumulative_ms": 0.509
      },
      {
        "module": "litellm.llms.openai.chat.gpt_transformation",
        "self_us": 352,
        "cumulative_us": 503,
        "self_ms": 0.352,
        "cumulative_ms": 0.503
      },
      {
        "module": "tiktoken.model",
        "self_us": 95,
        "cumulative_us": 500,
        "self_ms": 0.095,
        "cumulative_ms": 0.5
      },
      {
        "module": "openai.types.beta.thread",
        "self_us": 499,
        "cumulative_us": 499,
        "self_ms": 0.499,
        "cumulative_ms": 0.499
      },
      {
        "module": "openai.types.responses.response_output_message_param",
        "self_us": 123,
        "cumulative_us": 496,
        "self_ms": 0.123,
        "cumulative_ms": 0.496
      },
      {
        "module": "openai.types.beta.thread_create_and_run_params",
        "self_us": 491,
        "cumulative_us": 491,
        "self_ms": 0.491,
        "cumulative_ms": 0.491
      },
      {
        "module": "openai.types.audio.transcription_text_done_event",
        "self_us": 485,
        "cumulative_us": 485,
        "self_ms": 0.485,
        "cumulative_ms": 0.485
      },
      {
        "module": "pydantic.config",
        "self_us": 484,
        "cumulative_us": 484,
        "self_ms": 0.484,
        "cumulative_ms": 0.484
      },
      {
        "module": "openai.types.vector_store",
        "self_us": 484,
        "cumulative_us": 484,
        "self_ms": 0.484,
        "cumulative_ms": 0.484
      },
      {
        "module": "openai.lib",
        "self_us": 77,
        "cumulative_us": 484,
        "self_ms": 0.077,
        "cumulative_ms": 0.484
      },
      {
        "module": "pydantic._internal._decorators_v1",
        "self_us": 482,
        "cumulative_us": 482,
        "self_ms": 0.482,
        "cumulative_ms": 0.482
      },
      {
        "module": "pydantic_settings.sources.utils",
        "self_us": 481,
        "cumulative_us": 481,
        "self_ms": 0.481,
        "cumulative_ms": 0.481
      },
      {
        "module": "openai.types.graders.score_model_grader",
        "self_us": 477,
        "cumulative_us": 477,
        "self_ms": 0.477,
        "cumulative_ms": 0.477
      },
      {
        "module": "openai.types.beta.threads.runs.file_search_tool_call",
        "self_us": 476,
        "cumulative_us": 476,
        "self_ms": 0.476,
        "cumulative_ms": 0.476
      },
      {
        "module": "openai.types.chat.chat_completion_user_message_param",
        "self_us": 116,
        "cumulative_us": 475,
        "self_ms": 0.116,
        "cumulative_ms": 0.475
      },
      {
        "module": "httpx._status_codes",
        "self_us": 468,
        "cumulative_us": 468,
        "self_ms": 0.468,
        "cumulative_ms": 0.468
      },
      {
        "module": "openai.types.responses.response_text_config",
        "self_us": 162,
        "cumulative_us": 466,
        "self_ms": 0.162,
        "cumulative_ms": 0.466
      },
      {
        "module": "openai.types.image_gen_completed_event",
        "self_us": 457,
        "cumulative_us": 457,
        "self_ms": 0.457,
        "cumulative_ms": 0.457
      },
      {
        "module": "openai.types.vector_store_create_params",
        "self_us": 127,
        "cumulative_us": 453,
        "self_ms": 0.127,
        "cumulative_ms": 0.453
      },
      {
        "module": "openai.types.responses.easy_input_message_param",
        "self_us": 99,
        "cumulative_us": 452,
        "self_ms": 0.099,
        "cumulative_ms": 0.452
      },
      {
        "module": "openai.types.upload",
        "self_us": 224,
        "cumulative_us": 451,
        "self_ms": 0.224,
        "cumulative_ms": 0.451
      },
      {
        "module": "pydantic.plugin._schema_validator",
        "self_us": 168,
        "cumulative_us": 447,
        "self_ms": 0.168,
        "cumulative_ms": 0.447
      },
      {
        "module": "openai.types.responses.response_function_web_search",
        "self_us": 439,
        "cumulative_us": 439,
        "self_ms": 0.439,
        "cumulative_ms": 0.439
      },
      {
        "module": "httpx_sse",
        "self_us": 107,
        "cumulative_us": 438,
        "self_ms": 0.107,
        "cumulative_ms": 0.438
      },
      {
        "module": "pydantic._internal._typing_extra",
        "self_us": 252,
        "cumulative_us": 431,
        "self_ms": 0.252,
        "cumulative_ms": 0.431
      },
      {
        "module": "openai.types.beta.threads.runs.code_interpreter_tool_call",
        "self_us": 427,
        "cumulative_us": 427,
        "self_ms": 0.427,
        "cumulative_ms": 0.427
      },
      {
        "module": "litellm.llms.anthropic.experimental_pass_through.adapters",
        "self_us": 57,
        "cumulative_us": 421,
        "self_ms": 0.057,
        "cumulative_ms": 0.421
      },
      {
        "module": "httpx._transports.asgi",
        "self_us": 175,
        "cumulative_us": 414,
        "self_ms": 0.175,
        "cumulative_ms": 0.414
      },
      {
        "module": "pydantic_settings.sources.providers.cli",
        "self_us": 412,
        "cumulative_us": 412,
        "self_ms": 0.412,
        "cumulative_ms": 0.412
      },
      {
        "module": "openai.types.responses.response_code_interpreter_tool_call",
        "self_us": 407,
        "cumulative_us": 407,
        "self_ms": 0.407,
        "cumulative_ms": 0.407
      },
      {
        "module": "tiktoken.registry",
        "self_us": 80,
        "cumulative_us": 405,
        "self_ms": 0.08,
        "cumulative_ms": 0.405
      },
      {
        "module": "openai.types.responses.file_search_tool",
        "self_us": 403,
        "cumulative_us": 403,
        "self_ms": 0.403,
        "cumulative_ms": 0.403
      },
      {
        "module": "openai.types.images_response",
        "self_us": 399,
        "cumulative_us": 399,
        "self_ms": 0.399,
        "cumulative_ms": 0.399
      },
      {
        "module": "openai.types.shared.function_definition",
        "self_us": 348,
        "cumulative_us": 394,
        "self_ms": 0.348,
        "cumulative_ms": 0.394
      },
      {
        "module": "openai.types.responses.response_computer_tool_call_param",
        "self_us": 391,
        "cumulative_us": 391,
        "self_ms": 0.391,
        "cumulative_ms": 0.391
      },
      {
        "module": "openai.types.moderation_create_params",
        "self_us": 117,
        "cumulative_us": 389,
        "self_ms": 0.117,
        "cumulative_ms": 0.389
      },
      {
        "module": "openai._response",
        "self_us": 389,
        "cumulative_us": 389,
        "self_ms": 0.389,
        "cumulative_ms": 0.389
      },
      {
        "module": "pydantic.v1.config",
        "self_us": 387,
        "cumulative_us": 387,
        "self_ms": 0.387,
        "cumulative_ms": 0.387
      },
      {
        "module": "openai.types.fine_tuning.reinforcement_method",
        "self_us": 166,
        "cumulative_us": 387,
        "self_ms": 0.166,
        "cumulative_ms": 0.387
      },
      {
        "module": "openai.types.beta.threads.file_citation_delta_annotation",
        "self_us": 381,
        "cumulative_us": 381,
        "self_ms": 0.381,
        "cumulative_ms": 0.381
      },
      {
        "module": "openai.types.image_edit_completed_event",
        "self_us": 374,
        "cumulative_us": 374,
        "self_ms": 0.374,
        "cumulative_ms": 0.374
      },
      {
        "module": "openai.types.shared.compound_filter",
        "self_us": 179,
        "cumulative_us": 373,
        "self_ms": 0.179,
        "cumulative_ms": 0.373
      },
      {
        "module": "openai.types.beta.assistant_tool_choice_option",
        "self_us": 92,
        "cumulative_us": 373,
        "self_ms": 0.092,
        "cumulative_ms": 0.373
      },
      {
        "module": "litellm.llms.anthropic.experimental_pass_through.adapters.transformation",
        "self_us": 253,
        "cumulative_us": 365,
        "self_ms": 0.253,
        "cumulative_ms": 0.365
      },
      {
        "module": "pydantic.v1.fields",
        "self_us": 360,
        "cumulative_us": 360,
        "self_ms": 0.36,
        "cumulative_ms": 0.36
      },
      {
        "module": "pydantic.v1.schema",
        "self_us": 360,
        "cumulative_us": 360,
        "self_ms": 0.36,
        "cumulative_ms": 0.36
      },
      {
        "module": "openai.types.chat.chat_completion_content_part_param",
        "self_us": 124,
        "cumulative_us": 360,
        "self_ms": 0.124,
        "cumulative_ms": 0.36
      },
      {
        "module": "openai.types.responses.response_file_search_tool_call",
        "self_us": 358,
        "cumulative_us": 358,
        "self_ms": 0.358,
        "cumulative_ms": 0.358
      },
      {
        "module": "openai.types.responses.response_input_message_content_list_param",
        "self_us": 79,
        "cumulative_us": 354,
        "self_ms": 0.079,
        "cumulative_ms": 0.354
      },
      {
        "module": "openai.types.beta.file_search_tool",
        "self_us": 353,
        "cumulative_us": 353,
        "self_ms": 0.353,
        "cumulative_ms": 0.353
      },
      {
        "module": "openai.types.beta.threads.message_content_part_param",
        "self_us": 97,
        "cumulative_us": 353,
        "self_ms": 0.097,
        "cumulative_ms": 0.353
      },
      {
        "module": "litellm.llms.anthropic.chat.transformation",
        "self_us": 352,
        "cumulative_us": 352,
        "self_ms": 0.352,
        "cumulative_ms": 0.352
      },
      {
        "module": "openai.types.audio.transcription_segment",
        "self_us": 349,
        "cumulative_us": 349,
        "self_ms": 0.349,
        "cumulative_ms": 0.349
      },
      {
        "module": "openai.types.fine_tuning.dpo_hyperparameters",
        "self_us": 347,
        "cumulative_us": 347,
        "self_ms": 0.347,
        "cumulative_ms": 0.347
      },
      {
        "module": "openai.types.chat.chat_completion_assistant_message_param",
        "self_us": 161,
        "cumulative_us": 344,
        "self_ms": 0.161,
        "cumulative_ms": 0.344
      },
      {
        "module": "openai.types.completion_usage",
        "self_us": 343,
        "cumulative_us": 343,
        "self_ms": 0.343,
        "cumulative_ms": 0.343
      },
      {
        "module": "pydantic._internal._forward_ref",
        "self_us": 341,
        "cumulative_us": 341,
        "self_ms": 0.341,
        "cumulative_ms": 0.341
      },
      {
        "module": "openai.types.responses.easy_input_message",
        "self_us": 188,
        "cumulative_us": 333,
        "self_ms": 0.188,
        "cumulative_ms": 0.333
      },
      {
        "module": "openai.types.responses.response_text_done_event",
        "self_us": 333,
        "cumulative_us": 333,
        "self_ms": 0.333,
        "cumulative_ms": 0.333
      },
      {
        "module": "openai.types.responses.response_text_delta_event",
        "self_us": 332,
        "cumulative_us": 332,
        "self_ms": 0.332,
        "cumulative_ms": 0.332
      },
      {
        "module": "httpx_sse._api",
        "self_us": 133,
        "cumulative_us": 331,
        "self_ms": 0.133,
        "cumulative_ms": 0.331
      },
      {
        "module": "httpx._exceptions",
        "self_us": 330,
        "cumulative_us": 330,
        "self_ms": 0.33,
        "cumulative_ms": 0.33
      },
      {
        "module": "openai.types.static_file_chunking_strategy_object",
        "self_us": 176,
        "cumulative_us": 328,
        "self_ms": 0.176,
        "cumulative_ms": 0.328
      },
      {
        "module": "openai.types.container_list_response",
        "self_us": 327,
        "cumulative_us": 327,
        "self_ms": 0.327,
        "cumulative_ms": 0.327
      },
      {
        "module": "openai.types.file_chunking_strategy_param",
        "self_us": 68,
        "cumulative_us": 327,
        "self_ms": 0.068,
        "cumulative_ms": 0.327
      },
      {
        "module": "openai.types.fine_tuning.fine_tuning_job_wandb_integration_object",
        "self_us": 159,
        "cumulative_us": 325,
        "self_ms": 0.159,
        "cumulative_ms": 0.325
      },
      {
        "module": "openai.types.beta.threads.image_url_delta_block",
        "self_us": 178,
        "cumulative_us": 321,
        "self_ms": 0.178,
        "cumulative_ms": 0.321
      },
      {
        "module": "openai.types.beta.threads.image_url_content_block",
        "self_us": 152,
        "cumulative_us": 320,
        "self_ms": 0.152,
        "cumulative_ms": 0.32
      },
      {
        "module": "openai.types.shared.response_format_json_schema",
        "self_us": 317,
        "cumulative_us": 317,
        "self_ms": 0.317,
        "cumulative_ms": 0.317
      },
      {
        "module": "openai.types.responses.response_queued_event",
        "self_us": 316,
        "cumulative_us": 316,
        "self_ms": 0.316,
        "cumulative_ms": 0.316
      },
      {
        "module": "openai.types.responses.response_usage",
        "self_us": 312,
        "cumulative_us": 312,
        "self_ms": 0.312,
        "cumulative_ms": 0.312
      },
      {
        "module": "openai.types.completion_choice",
        "self_us": 311,
        "cumulative_us": 311,
        "self_ms": 0.311,
        "cumulative_ms": 0.311
      },
      {
        "module": "openai.types.responses.response_image_gen_call_partial_image_event",
        "self_us": 307,
        "cumulative_us": 307,
        "self_ms": 0.307,
        "cumulative_ms": 0.307
      },
      {
        "module": "pydantic._internal._schema_gather",
        "self_us": 306,
        "cumulative_us": 306,
        "self_ms": 0.306,
        "cumulative_ms": 0.306
      },
      {
        "module": "openai.types.responses.response_format_text_config",
        "self_us": 85,
        "cumulative_us": 304,
        "self_ms": 0.085,
        "cumulative_ms": 0.304
      },
      {
        "module": "openai.types.beta.threads.required_action_function_tool_call",
        "self_us": 301,
        "cumulative_us": 301,
        "self_ms": 0.301,
        "cumulative_ms": 0.301
      },
      {
        "module": "openai.types.responses.response_output_text_param",
        "self_us": 297,
        "cumulative_us": 297,
        "self_ms": 0.297,
        "cumulative_ms": 0.297
      },
      {
        "module": "pydantic._internal._schema_generation_shared",
        "self_us": 296,
        "cumulative_us": 296,
        "self_ms": 0.296,
        "cumulative_ms": 0.296
      },
      {
        "module": "openai.types.beta.threads.image_file_delta_block",
        "self_us": 164,
        "cumulative_us": 295,
        "self_ms": 0.164,
        "cumulative_ms": 0.295
      },
      {
        "module": "openai.types.audio.translation",
        "self_us": 291,
        "cumulative_us": 291,
        "self_ms": 0.291,
        "cumulative_ms": 0.291
      },
      {
        "module": "openai.types.shared.all_models",
        "self_us": 139,
        "cumulative_us": 290,
        "self_ms": 0.139,
        "cumulative_ms": 0.29
      },
      {
        "module": "openai.types.audio.transcription_verbose",
        "self_us": 286,
        "cumulative_us": 286,
        "self_ms": 0.286,
        "cumulative_ms": 0.286
      },
      {
        "module": "openai.types.responses.response_reasoning_item",
        "self_us": 284,
        "cumulative_us": 284,
        "self_ms": 0.284,
        "cumulative_ms": 0.284
      },
      {
        "module": "openai.types.beta.threads.image_file_content_block",
        "self_us": 148,
        "cumulative_us": 282,
        "self_ms": 0.148,
        "cumulative_ms": 0.282
      },
      {
        "module": "openai.types.beta.assistant_create_params",
        "self_us": 282,
        "cumulative_us": 282,
        "self_ms": 0.282,
        "cumulative_ms": 0.282
      },
      {
        "module": "openai.types.beta.assistant_tool_choice",
        "self_us": 164,
        "cumulative_us": 281,
        "self_ms": 0.164,
        "cumulative_ms": 0.281
      },
      {
        "module": "pydantic.plugin",
        "self_us": 280,
        "cumulative_us": 280,
        "self_ms": 0.28,
        "cumulative_ms": 0.28
      },
      {
        "module": "litellm.llms.custom_httpx.aiohttp_transport",
        "self_us": 280,
        "cumulative_us": 280,
        "self_ms": 0.28,
        "cumulative_ms": 0.28
      },
      {
        "module": "openai.types.fine_tuning.supervised_method",
        "self_us": 130,
        "cumulative_us": 279,
        "self_ms": 0.13,
        "cumulative_ms": 0.279
      },
      {
        "module": "openai.types.responses.response_mcp_call_failed_event",
        "self_us": 277,
        "cumulative_us": 277,
        "self_ms": 0.277,
        "cumulative_ms": 0.277
      },
      {
        "module": "openai.types.container_create_response",
        "self_us": 276,
        "cumulative_us": 276,
        "self_ms": 0.276,
        "cumulative_ms": 0.276
      },
      {
        "module": "openai.types.audio.transcription_text_delta_event",
        "self_us": 274,
        "cumulative_us": 274,
        "self_ms": 0.274,
        "cumulative_ms": 0.274
      },
      {
        "module": "httpx._decoders",
        "self_us": 159,
        "cumulative_us": 272,
        "self_ms": 0.159,
        "cumulative_ms": 0.272
      },
      {
        "module": "openai.types.responses.response_computer_tool_call_output_item",
        "self_us": 272,
        "cumulative_us": 272,
        "self_ms": 0.272,
        "cumulative_ms": 0.272
      },
      {
        "module": "openai.types.moderation_multi_modal_input_param",
        "self_us": 73,
        "cumulative_us": 272,
        "self_ms": 0.073,
        "cumulative_ms": 0.272
      },
      {
        "module": "openai.types.vector_store_search_response",
        "self_us": 272,
        "cumulative_us": 272,
        "self_ms": 0.272,
        "cumulative_ms": 0.272
      },
      {
        "module": "openai.types.beta.threads.file_path_delta_annotation",
        "self_us": 268,
        "cumulative_us": 268,
        "self_ms": 0.268,
        "cumulative_ms": 0.268
      },
      {
        "module": "openai.types.chat.chat_completion_token_logprob",
        "self_us": 265,
        "cumulative_us": 265,
        "self_ms": 0.265,
        "cumulative_ms": 0.265
      },
      {
        "module": "openai.types.container_retrieve_response",
        "self_us": 261,
        "cumulative_us": 261,
        "self_ms": 0.261,
        "cumulative_ms": 0.261
      },
      {
        "module": "openai.types.beta.threads.file_citation_annotation",
        "self_us": 261,
        "cumulative_us": 261,
        "self_ms": 0.261,
        "cumulative_ms": 0.261
      },
      {
        "module": "openai.types.create_embedding_response",
        "self_us": 260,
        "cumulative_us": 260,
        "self_ms": 0.26,
        "cumulative_ms": 0.26
      },
      {
        "module": "openai.types.beta.assistant_tool_param",
        "self_us": 68,
        "cumulative_us": 260,
        "self_ms": 0.068,
        "cumulative_ms": 0.26
      },
      {
        "module": "httpx._transports.default",
        "self_us": 257,
        "cumulative_us": 257,
        "self_ms": 0.257,
        "cumulative_ms": 0.257
      },
      {
        "module": "openai.types.responses.web_search_tool",
        "self_us": 255,
        "cumulative_us": 255,
        "self_ms": 0.255,
        "cumulative_ms": 0.255
      },
      {
        "module": "pydantic.v1.color",
        "self_us": 254,
        "cumulative_us": 254,
        "self_ms": 0.254,
        "cumulative_ms": 0.254
      },
      {
        "module": "litellm.types.proxy.guardrails.guardrail_hooks.openai",
        "self_us": 73,
        "cumulative_us": 251,
        "self_ms": 0.073,
        "cumulative_ms": 0.251
      },
      {
        "module": "openai.types.shared.reasoning",
        "self_us": 184,
        "cumulative_us": 250,
        "self_ms": 0.184,
        "cumulative_ms": 0.25
      },
      {
        "module": "litellm.litellm_core_utils.get_supported_openai_params",
        "self_us": 249,
        "cumulative_us": 249,
        "self_ms": 0.249,
        "cumulative_ms": 0.249
      },
      {
        "module": "litellm.llms.custom_httpx",
        "self_us": 110,
        "cumulative_us": 248,
        "self_ms": 0.11,
        "cumulative_ms": 0.248
      },
      {
        "module": "openai.types.beta.threads.file_path_annotation",
        "self_us": 248,
        "cumulative_us": 248,
        "self_ms": 0.248,
        "cumulative_ms": 0.248
      },
      {
        "module": "openai.types.shared.error_object",
        "self_us": 247,
        "cumulative_us": 247,
        "self_ms": 0.247,
        "cumulative_ms": 0.247
      },
      {
        "module": "openai.types.responses.response_mcp_call_arguments_delta_event",
        "self_us": 245,
        "cumulative_us": 245,
        "self_ms": 0.245,
        "cumulative_ms": 0.245
      },
      {
        "module": "openai.lib.azure",
        "self_us": 245,
        "cumulative_us": 245,
        "self_ms": 0.245,
        "cumulative_ms": 0.245
      },
      {
        "module": "openai.types.chat.parsed_function_tool_call",
        "self_us": 244,
        "cumulative_us": 244,
        "self_ms": 0.244,
        "cumulative_ms": 0.244
      },
      {
        "module": "litellm.llms.openai.responses.transformation",
        "self_us": 213,
        "cumulative_us": 244,
        "self_ms": 0.213,
        "cumulative_ms": 0.244
      },
      {
        "module": "openai.types.responses.response_reasoning_summary_part_done_event",
        "self_us": 243,
        "cumulative_us": 243,
        "self_ms": 0.243,
        "cumulative_ms": 0.243
      },
      {
        "module": "pydantic.v1.typing",
        "self_us": 241,
        "cumulative_us": 241,
        "self_ms": 0.241,
        "cumulative_ms": 0.241
      },
      {
        "module": "litellm.types.llms.anthropic_messages.anthropic_request",
        "self_us": 241,
        "cumulative_us": 241,
        "self_ms": 0.241,
        "cumulative_ms": 0.241
      },
      {
        "module": "openai.types.beta.threads.runs.file_search_tool_call_delta",
        "self_us": 240,
        "cumulative_us": 240,
        "self_ms": 0.24,
        "cumulative_ms": 0.24
      },
      {
        "module": "httpx._transports.base",
        "self_us": 239,
        "cumulative_us": 239,
        "self_ms": 0.239,
        "cumulative_ms": 0.239
      },
      {
        "module": "openai.types.beta.assistant_tool_choice_option_param",
        "self_us": 87,
        "cumulative_us": 238,
        "self_ms": 0.087,
        "cumulative_ms": 0.238
      },
      {
        "module": "openai.types.responses.response_reasoning_summary_part_added_event",
        "self_us": 237,
        "cumulative_us": 237,
        "self_ms": 0.237,
        "cumulative_ms": 0.237
      },
      {
        "module": "openai.types.audio.transcription_create_params",
        "self_us": 237,
        "cumulative_us": 237,
        "self_ms": 0.237,
        "cumulative_ms": 0.237
      },
      {
        "module": "openai.types.responses.response_item_list",
        "self_us": 236,
        "cumulative_us": 236,
        "self_ms": 0.236,
        "cumulative_ms": 0.236
      },
      {
        "module": "litellm.llms.vertex_ai.vertex_ai_partner_models.anthropic.transformation",
        "self_us": 115,
        "cumulative_us": 233,
        "self_ms": 0.115,
        "cumulative_ms": 0.233
      },
      {
        "module": "openai.types.image_gen_partial_image_event",
        "self_us": 232,
        "cumulative_us": 232,
        "self_ms": 0.232,
        "cumulative_ms": 0.232
      },
      {
        "module": "litellm.integrations.anthropic_cache_control_hook",
        "self_us": 117,
        "cumulative_us": 232,
        "self_ms": 0.117,
        "cumulative_ms": 0.232
      },
      {
        "module": "litellm.llms.aiohttp_openai.chat.transformation",
        "self_us": 124,
        "cumulative_us": 231,
        "self_ms": 0.124,
        "cumulative_ms": 0.231
      },
      {
        "module": "openai.types.beta.threads.runs.function_tool_call_delta",
        "self_us": 229,
        "cumulative_us": 229,
        "self_ms": 0.229,
        "cumulative_ms": 0.229
      },
      {
        "module": "pydantic.dataclasses",
        "self_us": 130,
        "cumulative_us": 229,
        "self_ms": 0.13,
        "cumulative_ms": 0.229
      },
      {
        "module": "openai.types.file_object",
        "self_us": 228,
        "cumulative_us": 228,
        "self_ms": 0.228,
        "cumulative_ms": 0.228
      },
      {
        "module": "openai.types.responses.response_text_config_param",
        "self_us": 70,
        "cumulative_us": 224,
        "self_ms": 0.07,
        "cumulative_ms": 0.224
      },
      {
        "module": "litellm.llms.anthropic.experimental_pass_through.messages.transformation",
        "self_us": 136,
        "cumulative_us": 224,
        "self_ms": 0.136,
        "cumulative_ms": 0.224
      },
      {
        "module": "openai.types.fine_tuning.reinforcement_hyperparameters",
        "self_us": 222,
        "cumulative_us": 222,
        "self_ms": 0.222,
        "cumulative_ms": 0.222
      },
      {
        "module": "openai.types.image",
        "self_us": 221,
        "cumulative_us": 221,
        "self_ms": 0.221,
        "cumulative_ms": 0.221
      },
      {
        "module": "openai._exceptions",
        "self_us": 221,
        "cumulative_us": 221,
        "self_ms": 0.221,
        "cumulative_ms": 0.221
      },
      {
        "module": "openai.types.responses.response_format_text_json_schema_config",
        "self_us": 220,
        "cumulative_us": 220,
        "self_ms": 0.22,
        "cumulative_ms": 0.22
      },
      {
        "module": "openai.lib._tools",
        "self_us": 140,
        "cumulative_us": 220,
        "self_ms": 0.14,
        "cumulative_ms": 0.22
      },
      {
        "module": "openai.types.beta.threads.runs.function_tool_call",
        "self_us": 220,
        "cumulative_us": 220,
        "self_ms": 0.22,
        "cumulative_ms": 0.22
      },
      {
        "module": "openai.types.image_edit_params",
        "self_us": 218,
        "cumulative_us": 218,
        "self_ms": 0.218,
        "cumulative_ms": 0.218
      },
      {
        "module": "openai.types.other_file_chunking_strategy_object",
        "self_us": 217,
        "cumulative_us": 217,
        "self_ms": 0.217,
        "cumulative_ms": 0.217
      },
      {
        "module": "openai.types.chat.chat_completion_store_message",
        "self_us": 216,
        "cumulative_us": 216,
        "self_ms": 0.216,
        "cumulative_ms": 0.216
      },
      {
        "module": "pydantic_settings.sources.providers.aws",
        "self_us": 114,
        "cumulative_us": 213,
        "self_ms": 0.114,
        "cumulative_ms": 0.213
      },
      {
        "module": "openai.types.fine_tuning.reinforcement_method_param",
        "self_us": 99,
        "cumulative_us": 211,
        "self_ms": 0.099,
        "cumulative_ms": 0.211
      },
      {
        "module": "openai.types.fine_tuning.fine_tuning_job_event",
        "self_us": 211,
        "cumulative_us": 211,
        "self_ms": 0.211,
        "cumulative_ms": 0.211
      },
      {
        "module": "openai.types.chat.chat_completion_message_tool_call",
        "self_us": 210,
        "cumulative_us": 210,
        "self_ms": 0.21,
        "cumulative_ms": 0.21
      },
      {
        "module": "openai.types.responses.response_content_part_done_event",
        "self_us": 210,
        "cumulative_us": 210,
        "self_ms": 0.21,
        "cumulative_ms": 0.21
      },
      {
        "module": "openai.types.image_edit_partial_image_event",
        "self_us": 210,
        "cumulative_us": 210,
        "self_ms": 0.21,
        "cumulative_ms": 0.21
      },
      {
        "module": "openai.types.image_generate_params",
        "self_us": 208,
        "cumulative_us": 208,
        "self_ms": 0.208,
        "cumulative_ms": 0.208
      },
      {
        "module": "openai.types.beta.threads.runs.code_interpreter_output_image",
        "self_us": 201,
        "cumulative_us": 201,
        "self_ms": 0.201,
        "cumulative_ms": 0.201
      },
      {
        "module": "openai.types.responses.response_input_message_item",
        "self_us": 200,
        "cumulative_us": 200,
        "self_ms": 0.2,
        "cumulative_ms": 0.2
      },
      {
        "module": "openai.types.responses.response_output_text_annotation_added_event",
        "self_us": 200,
        "cumulative_us": 200,
        "self_ms": 0.2,
        "cumulative_ms": 0.2
      },
      {
        "module": "litellm.llms.anthropic.completion.transformation",
        "self_us": 167,
        "cumulative_us": 200,
        "self_ms": 0.167,
        "cumulative_ms": 0.2
      },
      {
        "module": "openai.types.chat.chat_completion_tool_message_param",
        "self_us": 95,
        "cumulative_us": 198,
        "self_ms": 0.095,
        "cumulative_ms": 0.198
      },
      {
        "module": "openai.types.beta.threads.runs.run_step_delta_message_delta",
        "self_us": 198,
        "cumulative_us": 198,
        "self_ms": 0.198,
        "cumulative_ms": 0.198
      },
      {
        "module": "openai.types.beta.assistant_update_params",
        "self_us": 198,
        "cumulative_us": 198,
        "self_ms": 0.198,
        "cumulative_ms": 0.198
      },
      {
        "module": "openai._utils._transform",
        "self_us": 124,
        "cumulative_us": 196,
        "self_ms": 0.124,
        "cumulative_ms": 0.196
      },
      {
        "module": "openai.types.responses.response_output_item_done_event",
        "self_us": 196,
        "cumulative_us": 196,
        "self_ms": 0.196,
        "cumulative_ms": 0.196
      },
      {
        "module": "openai.types.shared.comparison_filter",
        "self_us": 195,
        "cumulative_us": 195,
        "self_ms": 0.195,
        "cumulative_ms": 0.195
      },
      {
        "module": "openai.types.responses.response_function_tool_call",
        "self_us": 195,
        "cumulative_us": 195,
        "self_ms": 0.195,
        "cumulative_ms": 0.195
      },
      {
        "module": "litellm.anthropic_interface",
        "self_us": 77,
        "cumulative_us": 195,
        "self_ms": 0.077,
        "cumulative_ms": 0.195
      },
      {
        "module": "openai._streaming",
        "self_us": 194,
        "cumulative_us": 194,
        "self_ms": 0.194,
        "cumulative_ms": 0.194
      },
      {
        "module": "openai.types.graders.label_model_grader_param",
        "self_us": 192,
        "cumulative_us": 192,
        "self_ms": 0.192,
        "cumulative_ms": 0.192
      },
      {
        "module": "openai.types.graders.score_model_grader_param",
        "self_us": 192,
        "cumulative_us": 192,
        "self_ms": 0.192,
        "cumulative_ms": 0.192
      },
      {
        "module": "openai.types.batch_error",
        "self_us": 190,
        "cumulative_us": 190,
        "self_ms": 0.19,
        "cumulative_ms": 0.19
      },
      {
        "module": "openai.types.responses.response_content_part_added_event",
        "self_us": 190,
        "cumulative_us": 190,
        "self_ms": 0.19,
        "cumulative_ms": 0.19
      },
      {
        "module": "openai.types.beta.threads.runs.message_creation_step_details",
        "self_us": 189,
        "cumulative_us": 189,
        "self_ms": 0.189,
        "cumulative_ms": 0.189
      },
      {
        "module": "litellm.llms.openai.fine_tuning.handler",
        "self_us": 149,
        "cumulative_us": 189,
        "self_ms": 0.149,
        "cumulative_ms": 0.189
      },
      {
        "module": "openai.lib._parsing",
        "self_us": 62,
        "cumulative_us": 187,
        "self_ms": 0.062,
        "cumulative_ms": 0.187
      },
      {
        "module": "openai.types.responses.response_failed_event",
        "self_us": 186,
        "cumulative_us": 186,
        "self_ms": 0.186,
        "cumulative_ms": 0.186
      },
      {
        "module": "openai._legacy_response",
        "self_us": 186,
        "cumulative_us": 186,
        "self_ms": 0.186,
        "cumulative_ms": 0.186
      },
      {
        "module": "openai.types.responses.response_input_image",
        "self_us": 185,
        "cumulative_us": 185,
        "self_ms": 0.185,
        "cumulative_ms": 0.185
      },
      {
        "module": "openai.types.responses.response_error_event",
        "self_us": 185,
        "cumulative_us": 185,
        "self_ms": 0.185,
        "cumulative_ms": 0.185
      },
      {
        "module": "openai.types.responses.response_input_file",
        "self_us": 184,
        "cumulative_us": 184,
        "self_ms": 0.184,
        "cumulative_ms": 0.184
      },
      {
        "module": "openai.types.model",
        "self_us": 182,
        "cumulative_us": 182,
        "self_ms": 0.182,
        "cumulative_ms": 0.182
      },
      {
        "module": "openai.types.graders.text_similarity_grader",
        "self_us": 182,
        "cumulative_us": 182,
        "self_ms": 0.182,
        "cumulative_ms": 0.182
      },
      {
        "module": "openai.types.static_file_chunking_strategy_object_param",
        "self_us": 98,
        "cumulative_us": 182,
        "self_ms": 0.098,
        "cumulative_ms": 0.182
      },
      {
        "module": "openai.types.responses.response_output_item_added_event",
        "self_us": 181,
        "cumulative_us": 181,
        "self_ms": 0.181,
        "cumulative_ms": 0.181
      },
      {
        "module": "openai.types.responses.response_function_tool_call_item",
        "self_us": 180,
        "cumulative_us": 180,
        "self_ms": 0.18,
        "cumulative_ms": 0.18
      },
      {
        "module": "pydantic._internal._namespace_utils",
        "self_us": 179,
        "cumulative_us": 179,
        "self_ms": 0.179,
        "cumulative_ms": 0.179
      },
      {
        "module": "openai.types.beta.threads.message_deleted",
        "self_us": 178,
        "cumulative_us": 178,
        "self_ms": 0.178,
        "cumulative_ms": 0.178
      },
      {
        "module": "openai.types.graders.string_check_grader",
        "self_us": 177,
        "cumulative_us": 177,
        "self_ms": 0.177,
        "cumulative_ms": 0.177
      },
      {
        "module": "openai.types.eval_custom_data_source_config",
        "self_us": 177,
        "cumulative_us": 177,
        "self_ms": 0.177,
        "cumulative_ms": 0.177
      },
      {
        "module": "litellm.llms.anthropic.batches.transformation",
        "self_us": 109,
        "cumulative_us": 177,
        "self_ms": 0.109,
        "cumulative_ms": 0.177
      },
      {
        "module": "openai.types.responses.response_function_web_search_param",
        "self_us": 176,
        "cumulative_us": 176,
        "self_ms": 0.176,
        "cumulative_ms": 0.176
      },
      {
        "module": "openai.types.audio.speech_create_params",
        "self_us": 175,
        "cumulative_us": 175,
        "self_ms": 0.175,
        "cumulative_ms": 0.175
      },
      {
        "module": "openai.types.beta.threads.text_delta_block",
        "self_us": 174,
        "cumulative_us": 174,
        "self_ms": 0.174,
        "cumulative_ms": 0.174
      },
      {
        "module": "litellm.llms.openai.common_utils",
        "self_us": 174,
        "cumulative_us": 174,
        "self_ms": 0.174,
        "cumulative_ms": 0.174
      },
      {
        "module": "openai.types.graders.python_grader",
        "self_us": 172,
        "cumulative_us": 172,
        "self_ms": 0.172,
        "cumulative_ms": 0.172
      },
      {
        "module": "openai.types.beta.threads.message_delta_event",
        "self_us": 171,
        "cumulative_us": 171,
        "self_ms": 0.171,
        "cumulative_ms": 0.171
      },
      {
        "module": "openai.types.shared_params.compound_filter",
        "self_us": 86,
        "cumulative_us": 170,
        "self_ms": 0.086,
        "cumulative_ms": 0.17
      },
      {
        "module": "openai.types.responses.response_refusal_delta_event",
        "self_us": 169,
        "cumulative_us": 169,
        "self_ms": 0.169,
        "cumulative_ms": 0.169
      },
      {
        "module": "openai.types.responses.response_mcp_call_arguments_done_event",
        "self_us": 169,
        "cumulative_us": 169,
        "self_ms": 0.169,
        "cumulative_ms": 0.169
      },
      {
        "module": "openai.types.eval_stored_completions_data_source_config",
        "self_us": 169,
        "cumulative_us": 169,
        "self_ms": 0.169,
        "cumulative_ms": 0.169
      },
      {
        "module": "openai.types.beta.threads.image_url",
        "self_us": 169,
        "cumulative_us": 169,
        "self_ms": 0.169,
        "cumulative_ms": 0.169
      },
      {
        "module": "litellm.llms.openai.image_variations.transformation",
        "self_us": 132,
        "cumulative_us": 169,
        "self_ms": 0.132,
        "cumulative_ms": 0.169
      },
      {
        "module": "openai.types.responses.function_tool",
        "self_us": 168,
        "cumulative_us": 168,
        "self_ms": 0.168,
        "cumulative_ms": 0.168
      },
      {
        "module": "openai.types.responses.response_web_search_call_in_progress_event",
        "self_us": 168,
        "cumulative_us": 168,
        "self_ms": 0.168,
        "cumulative_ms": 0.168
      },
      {
        "module": "openai.types.moderation_create_response",
        "self_us": 168,
        "cumulative_us": 168,
        "self_ms": 0.168,
        "cumulative_ms": 0.168
      },
      {
        "module": "openai.types.responses.response_reasoning_summary_done_event",
        "self_us": 167,
        "cumulative_us": 167,
        "self_ms": 0.167,
        "cumulative_ms": 0.167
      },
      {
        "module": "openai._qs",
        "self_us": 167,
        "cumulative_us": 167,
        "self_ms": 0.167,
        "cumulative_ms": 0.167
      },
      {
        "module": "openai.types.fine_tuning.fine_tuning_job_wandb_integration",
        "self_us": 167,
        "cumulative_us": 167,
        "self_ms": 0.167,
        "cumulative_ms": 0.167
      },
      {
        "module": "openai.types.responses.response_function_tool_call_output_item",
        "self_us": 164,
        "cumulative_us": 164,
        "self_ms": 0.164,
        "cumulative_ms": 0.164
      },
      {
        "module": "openai.types.responses.response_reasoning_summary_text_done_event",
        "self_us": 163,
        "cumulative_us": 163,
        "self_ms": 0.163,
        "cumulative_ms": 0.163
      },
      {
        "module": "openai.types.responses.response_function_call_arguments_done_event",
        "self_us": 163,
        "cumulative_us": 163,
        "self_ms": 0.163,
        "cumulative_ms": 0.163
      },
      {
        "module": "openai.types.beta.threads.refusal_content_block",
        "self_us": 163,
        "cumulative_us": 163,
        "self_ms": 0.163,
        "cumulative_ms": 0.163
      },
      {
        "module": "openai.types.fine_tuning.dpo_method_param",
        "self_us": 68,
        "cumulative_us": 163,
        "self_ms": 0.068,
        "cumulative_ms": 0.163
      },
      {
        "module": "openai.types.responses.response_prompt_param",
        "self_us": 162,
        "cumulative_us": 162,
        "self_ms": 0.162,
        "cumulative_ms": 0.162
      },
      {
        "module": "openai.types.beta.threads.refusal_delta_block",
        "self_us": 162,
        "cumulative_us": 162,
        "self_ms": 0.162,
        "cumulative_ms": 0.162
      },
      {
        "module": "openai.types.responses.response_error",
        "self_us": 161,
        "cumulative_us": 161,
        "self_ms": 0.161,
        "cumulative_ms": 0.161
      },
      {
        "module": "openai.types.responses.response_computer_tool_call_output_screenshot",
        "self_us": 161,
        "cumulative_us": 161,
        "self_ms": 0.161,
        "cumulative_ms": 0.161
      },
      {
        "module": "openai.types.responses.response_code_interpreter_call_code_done_event",
        "self_us": 161,
        "cumulative_us": 161,
        "self_ms": 0.161,
        "cumulative_ms": 0.161
      },
      {
        "module": "openai.types.chat.chat_completion_deleted",
        "self_us": 159,
        "cumulative_us": 159,
        "self_ms": 0.159,
        "cumulative_ms": 0.159
      },
      {
        "module": "openai.types.responses.response_refusal_done_event",
        "self_us": 159,
        "cumulative_us": 159,
        "self_ms": 0.159,
        "cumulative_ms": 0.159
      },
      {
        "module": "openai.types.responses.response_image_gen_call_generating_event",
        "self_us": 159,
        "cumulative_us": 159,
        "self_ms": 0.159,
        "cumulative_ms": 0.159
      },
      {
        "module": "pydantic._internal._core_metadata",
        "self_us": 158,
        "cumulative_us": 158,
        "self_ms": 0.158,
        "cumulative_ms": 0.158
      },
      {
        "module": "openai.types.responses.tool_choice_mcp",
        "self_us": 158,
        "cumulative_us": 158,
        "self_ms": 0.158,
        "cumulative_ms": 0.158
      },
      {
        "module": "openai.types.responses.response_code_interpreter_tool_call_param",
        "self_us": 158,
        "cumulative_us": 158,
        "self_ms": 0.158,
        "cumulative_ms": 0.158
      },
      {
        "module": "litellm.llms.anthropic.common_utils",
        "self_us": 158,
        "cumulative_us": 158,
        "self_ms": 0.158,
        "cumulative_ms": 0.158
      },
      {
        "module": "openai.types.responses.response_output_refusal",
        "self_us": 157,
        "cumulative_us": 157,
        "self_ms": 0.157,
        "cumulative_ms": 0.157
      },
      {
        "module": "openai.types.responses.response_input_text",
        "self_us": 156,
        "cumulative_us": 156,
        "self_ms": 0.156,
        "cumulative_ms": 0.156
      },
      {
        "module": "openai.types.responses.response_mcp_call_in_progress_event",
        "self_us": 156,
        "cumulative_us": 156,
        "self_ms": 0.156,
        "cumulative_ms": 0.156
      },
      {
        "module": "pydantic._internal._known_annotated_metadata",
        "self_us": 155,
        "cumulative_us": 155,
        "self_ms": 0.155,
        "cumulative_ms": 0.155
      },
      {
        "module": "pydantic._internal._signature",
        "self_us": 155,
        "cumulative_us": 155,
        "self_ms": 0.155,
        "cumulative_ms": 0.155
      },
      {
        "module": "openai.types.chat.chat_completion_tool_choice_option_param",
        "self_us": 71,
        "cumulative_us": 155,
        "self_ms": 0.071,
        "cumulative_ms": 0.155
      },
      {
        "module": "openai.types.responses.response_file_search_call_in_progress_event",
        "self_us": 155,
        "cumulative_us": 155,
        "self_ms": 0.155,
        "cumulative_ms": 0.155
      },
      {
        "module": "openai.types.responses.response_format_text_config_param",
        "self_us": 64,
        "cumulative_us": 155,
        "self_ms": 0.064,
        "cumulative_ms": 0.155
      },
      {
        "module": "litellm.llms.custom_httpx.aiohttp_handler",
        "self_us": 155,
        "cumulative_us": 155,
        "self_ms": 0.155,
        "cumulative_ms": 0.155
      },
      {
        "module": "openai.types.responses.computer_tool",
        "self_us": 154,
        "cumulative_us": 154,
        "self_ms": 0.154,
        "cumulative_ms": 0.154
      },
      {
        "module": "openai.types.responses.response_reasoning_summary_delta_event",
        "self_us": 154,
        "cumulative_us": 154,
        "self_ms": 0.154,
        "cumulative_ms": 0.154
      },
      {
        "module": "openai.types.responses.response_file_search_call_searching_event",
        "self_us": 154,
        "cumulative_us": 154,
        "self_ms": 0.154,
        "cumulative_ms": 0.154
      },
      {
        "module": "openai.types.responses.response_retrieve_params",
        "self_us": 154,
        "cumulative_us": 154,
        "self_ms": 0.154,
        "cumulative_ms": 0.154
      },
      {
        "module": "openai.types.batch_request_counts",
        "self_us": 153,
        "cumulative_us": 153,
        "self_ms": 0.153,
        "cumulative_ms": 0.153
      },
      {
        "module": "openai.types.embedding",
        "self_us": 153,
        "cumulative_us": 153,
        "self_ms": 0.153,
        "cumulative_ms": 0.153
      },
      {
        "module": "openai.types.responses.response_mcp_call_completed_event",
        "self_us": 153,
        "cumulative_us": 153,
        "self_ms": 0.153,
        "cumulative_ms": 0.153
      },
      {
        "module": "openai.types.responses.response_image_gen_call_in_progress_event",
        "self_us": 153,
        "cumulative_us": 153,
        "self_ms": 0.153,
        "cumulative_ms": 0.153
      },
      {
        "module": "openai.types.responses.response_reasoning_summary_text_delta_event",
        "self_us": 152,
        "cumulative_us": 152,
        "self_ms": 0.152,
        "cumulative_ms": 0.152
      },
      {
        "module": "openai.types.static_file_chunking_strategy",
        "self_us": 152,
        "cumulative_us": 152,
        "self_ms": 0.152,
        "cumulative_ms": 0.152
      },
      {
        "module": "openai.types.beta.assistant_tool_choice_param",
        "self_us": 89,
        "cumulative_us": 152,
        "self_ms": 0.089,
        "cumulative_ms": 0.152
      },
      {
        "module": "openai.types.shared.chat_model",
        "self_us": 151,
        "cumulative_us": 151,
        "self_ms": 0.151,
        "cumulative_ms": 0.151
      },
      {
        "module": "openai.types.audio.transcription_word",
        "self_us": 151,
        "cumulative_us": 151,
        "self_ms": 0.151,
        "cumulative_ms": 0.151
      },
      {
        "module": "openai.types.responses.response_image_gen_call_completed_event",
        "self_us": 150,
        "cumulative_us": 150,
        "self_ms": 0.15,
        "cumulative_ms": 0.15
      },
      {
        "module": "openai.types.responses.response_web_search_call_completed_event",
        "self_us": 149,
        "cumulative_us": 149,
        "self_ms": 0.149,
        "cumulative_ms": 0.149
      },
      {
        "module": "openai.types.responses.response_web_search_call_searching_event",
        "self_us": 149,
        "cumulative_us": 149,
        "self_ms": 0.149,
        "cumulative_ms": 0.149
      },
      {
        "module": "openai.types.beta.function_tool",
        "self_us": 149,
        "cumulative_us": 149,
        "self_ms": 0.149,
        "cumulative_ms": 0.149
      },
      {
        "module": "openai.types.beta.assistant_deleted",
        "self_us": 149,
        "cumulative_us": 149,
        "self_ms": 0.149,
        "cumulative_ms": 0.149
      },
      {
        "module": "openai.types.fine_tuning.supervised_hyperparameters",
        "self_us": 149,
        "cumulative_us": 149,
        "self_ms": 0.149,
        "cumulative_ms": 0.149
      },
      {
        "module": "pydantic._internal._discriminated_union",
        "self_us": 147,
        "cumulative_us": 147,
        "self_ms": 0.147,
        "cumulative_ms": 0.147
      },
      {
        "module": "openai.types.responses.response_audio_done_event",
        "self_us": 147,
        "cumulative_us": 147,
        "self_ms": 0.147,
        "cumulative_ms": 0.147
      },
      {
        "module": "openai.types.beta.thread_deleted",
        "self_us": 147,
        "cumulative_us": 147,
        "self_ms": 0.147,
        "cumulative_ms": 0.147
      },
      {
        "module": "openai.types.fine_tuning.supervised_method_param",
        "self_us": 67,
        "cumulative_us": 147,
        "self_ms": 0.067,
        "cumulative_ms": 0.147
      },
      {
        "module": "openai.types.shared.response_format_json_object",
        "self_us": 146,
        "cumulative_us": 146,
        "self_ms": 0.146,
        "cumulative_ms": 0.146
      },
      {
        "module": "openai.types.responses.response_mcp_list_tools_failed_event",
        "self_us": 146,
        "cumulative_us": 146,
        "self_ms": 0.146,
        "cumulative_ms": 0.146
      },
      {
        "module": "openai.types.responses.response_input_message_content_list",
        "self_us": 69,
        "cumulative_us": 145,
        "self_ms": 0.069,
        "cumulative_ms": 0.145
      },
      {
        "module": "openai.types.responses.computer_tool_param",
        "self_us": 145,
        "cumulative_us": 145,
        "self_ms": 0.145,
        "cumulative_ms": 0.145
      },
      {
        "module": "openai.types.responses.response_file_search_tool_call_param",
        "self_us": 145,
        "cumulative_us": 145,
        "self_ms": 0.145,
        "cumulative_ms": 0.145
      },
      {
        "module": "openai.types.responses.tool_choice_function",
        "self_us": 144,
        "cumulative_us": 144,
        "self_ms": 0.144,
        "cumulative_ms": 0.144
      },
      {
        "module": "openai.types.chat.chat_completion_audio",
        "self_us": 144,
        "cumulative_us": 144,
        "self_ms": 0.144,
        "cumulative_ms": 0.144
      },
      {
        "module": "openai.types.responses.response_mcp_list_tools_in_progress_event",
        "self_us": 144,
        "cumulative_us": 144,
        "self_ms": 0.144,
        "cumulative_ms": 0.144
      },
      {
        "module": "openai.types.beta.threads.image_url_delta",
        "self_us": 144,
        "cumulative_us": 144,
        "self_ms": 0.144,
        "cumulative_ms": 0.144
      },
      {
        "module": "openai.types.chat.chat_completion_tool",
        "self_us": 143,
        "cumulative_us": 143,
        "self_ms": 0.143,
        "cumulative_ms": 0.143
      },
      {
        "module": "openai.types.responses.response_created_event",
        "self_us": 143,
        "cumulative_us": 143,
        "self_ms": 0.143,
        "cumulative_ms": 0.143
      },
      {
        "module": "openai.types.responses.response_function_call_arguments_delta_event",
        "self_us": 143,
        "cumulative_us": 143,
        "self_ms": 0.143,
        "cumulative_ms": 0.143
      },
      {
        "module": "openai.types.responses.response_code_interpreter_call_code_delta_event",
        "self_us": 143,
        "cumulative_us": 143,
        "self_ms": 0.143,
        "cumulative_ms": 0.143
      },
      {
        "module": "openai.types.embedding_create_params",
        "self_us": 143,
        "cumulative_us": 143,
        "self_ms": 0.143,
        "cumulative_ms": 0.143
      },
      {
        "module": "openai.types.beta.threads.text_content_block",
        "self_us": 143,
        "cumulative_us": 143,
        "self_ms": 0.143,
        "cumulative_ms": 0.143
      },
      {
        "module": "openai.types.responses.web_search_tool_param",
        "self_us": 142,
        "cumulative_us": 142,
        "self_ms": 0.142,
        "cumulative_ms": 0.142
      },
      {
        "module": "openai.types.responses.file_search_tool_param",
        "self_us": 142,
        "cumulative_us": 142,
        "self_ms": 0.142,
        "cumulative_ms": 0.142
      },
      {
        "module": "openai.types.responses.response_audio_transcript_delta_event",
        "self_us": 142,
        "cumulative_us": 142,
        "self_ms": 0.142,
        "cumulative_ms": 0.142
      },
      {
        "module": "openai.types.responses.response_mcp_list_tools_completed_event",
        "self_us": 142,
        "cumulative_us": 142,
        "self_ms": 0.142,
        "cumulative_ms": 0.142
      },
      {
        "module": "openai.types.responses.response_file_search_call_completed_event",
        "self_us": 142,
        "cumulative_us": 142,
        "self_ms": 0.142,
        "cumulative_ms": 0.142
      },
      {
        "module": "openai.types.beta.code_interpreter_tool",
        "self_us": 142,
        "cumulative_us": 142,
        "self_ms": 0.142,
        "cumulative_ms": 0.142
      },
      {
        "module": "pydantic._internal._core_utils",
        "self_us": 141,
        "cumulative_us": 141,
        "self_ms": 0.141,
        "cumulative_ms": 0.141
      },
      {
        "module": "pydantic.v1.decorator",
        "self_us": 141,
        "cumulative_us": 141,
        "self_ms": 0.141,
        "cumulative_ms": 0.141
      },
      {
        "module": "openai.types.responses.response_completed_event",
        "self_us": 141,
        "cumulative_us": 141,
        "self_ms": 0.141,
        "cumulative_ms": 0.141
      },
      {
        "module": "openai.types.vector_store_search_params",
        "self_us": 141,
        "cumulative_us": 141,
        "self_ms": 0.141,
        "cumulative_ms": 0.141
      },
      {
        "module": "openai.types.responses.response_code_interpreter_call_completed_event",
        "self_us": 140,
        "cumulative_us": 140,
        "self_ms": 0.14,
        "cumulative_ms": 0.14
      },
      {
        "module": "openai.types.beta.threads.runs.code_interpreter_logs",
        "self_us": 140,
        "cumulative_us": 140,
        "self_ms": 0.14,
        "cumulative_ms": 0.14
      },
      {
        "module": "openai.types.container_create_params",
        "self_us": 139,
        "cumulative_us": 139,
        "self_ms": 0.139,
        "cumulative_ms": 0.139
      },
      {
        "module": "litellm.llms.openai_like.embedding.handler",
        "self_us": 107,
        "cumulative_us": 139,
        "self_ms": 0.107,
        "cumulative_ms": 0.139
      },
      {
        "module": "litellm.llms.openai.transcriptions.whisper_transformation",
        "self_us": 101,
        "cumulative_us": 138,
        "self_ms": 0.101,
        "cumulative_ms": 0.138
      },
      {
        "module": "openai.types.shared.response_format_text",
        "self_us": 137,
        "cumulative_us": 137,
        "self_ms": 0.137,
        "cumulative_ms": 0.137
      },
      {
        "module": "openai.types.responses.response_incomplete_event",
        "self_us": 137,
        "cumulative_us": 137,
        "self_ms": 0.137,
        "cumulative_ms": 0.137
      },
      {
        "module": "openai.types.responses.response_code_interpreter_call_interpreting_event",
        "self_us": 137,
        "cumulative_us": 137,
        "self_ms": 0.137,
        "cumulative_ms": 0.137
      },
      {
        "module": "openai.types.beta.threads.runs.run_step_delta_event",
        "self_us": 137,
        "cumulative_us": 137,
        "self_ms": 0.137,
        "cumulative_ms": 0.137
      },
      {
        "module": "httpx_sse._decoders",
        "self_us": 74,
        "cumulative_us": 137,
        "self_ms": 0.074,
        "cumulative_ms": 0.137
      },
      {
        "module": "openai.types.file_deleted",
        "self_us": 136,
        "cumulative_us": 136,
        "self_ms": 0.136,
        "cumulative_ms": 0.136
      },
      {
        "module": "openai.types.responses.response_audio_transcript_done_event",
        "self_us": 136,
        "cumulative_us": 136,
        "self_ms": 0.136,
        "cumulative_ms": 0.136
      },
      {
        "module": "httpx._transports.mock",
        "self_us": 135,
        "cumulative_us": 135,
        "self_ms": 0.135,
        "cumulative_ms": 0.135
      },
      {
        "module": "openai.types.model_deleted",
        "self_us": 134,
        "cumulative_us": 134,
        "self_ms": 0.134,
        "cumulative_ms": 0.134
      },
      {
        "module": "openai.types.beta.threads.image_file",
        "self_us": 134,
        "cumulative_us": 134,
        "self_ms": 0.134,
        "cumulative_ms": 0.134
      },
      {
        "module": "openai.types.beta.threads.message_create_params",
        "self_us": 134,
        "cumulative_us": 134,
        "self_ms": 0.134,
        "cumulative_ms": 0.134
      },
      {
        "module": "pydantic_settings.sources.providers.pyproject",
        "self_us": 70,
        "cumulative_us": 134,
        "self_ms": 0.07,
        "cumulative_ms": 0.134
      },
      {
        "module": "pydantic._internal._docs_extraction",
        "self_us": 133,
        "cumulative_us": 133,
        "self_ms": 0.133,
        "cumulative_ms": 0.133
      },
      {
        "module": "openai.types.responses.tool_choice_types",
        "self_us": 133,
        "cumulative_us": 133,
        "self_ms": 0.133,
        "cumulative_ms": 0.133
      },
      {
        "module": "openai.types.responses.response_code_interpreter_call_in_progress_event",
        "self_us": 133,
        "cumulative_us": 133,
        "self_ms": 0.133,
        "cumulative_ms": 0.133
      },
      {
        "module": "openai.types.vector_store_deleted",
        "self_us": 133,
        "cumulative_us": 133,
        "self_ms": 0.133,
        "cumulative_ms": 0.133
      },
      {
        "module": "pydantic.v1.parse",
        "self_us": 132,
        "cumulative_us": 132,
        "self_ms": 0.132,
        "cumulative_ms": 0.132
      },
      {
        "module": "openai.types.responses.response_audio_delta_event",
        "self_us": 132,
        "cumulative_us": 132,
        "self_ms": 0.132,
        "cumulative_ms": 0.132
      },
      {
        "module": "openai.types.responses.response_in_progress_event",
        "self_us": 132,
        "cumulative_us": 132,
        "self_ms": 0.132,
        "cumulative_ms": 0.132
      },
      {
        "module": "openai.types.websocket_connection_options",
        "self_us": 132,
        "cumulative_us": 132,
        "self_ms": 0.132,
        "cumulative_ms": 0.132
      },
      {
        "module": "litellm.llms.openai.realtime.handler",
        "self_us": 100,
        "cumulative_us": 132,
        "self_ms": 0.1,
        "cumulative_ms": 0.132
      },
      {
        "module": "openai.types.eval_delete_response",
        "self_us": 131,
        "cumulative_us": 131,
        "self_ms": 0.131,
        "cumulative_ms": 0.131
      },
      {
        "module": "openai.types.beta.threads.image_file_delta",
        "self_us": 131,
        "cumulative_us": 131,
        "self_ms": 0.131,
        "cumulative_ms": 0.131
      },
      {
        "module": "openai.types.beta.threads.run_submit_tool_outputs_params",
        "self_us": 131,
        "cumulative_us": 131,
        "self_ms": 0.131,
        "cumulative_ms": 0.131
      },
      {
        "module": "pydantic_settings.sources.types",
        "self_us": 130,
        "cumulative_us": 130,
        "self_ms": 0.13,
        "cumulative_ms": 0.13
      },
      {
        "module": "pydantic._internal._import_utils",
        "self_us": 129,
        "cumulative_us": 129,
        "self_ms": 0.129,
        "cumulative_ms": 0.129
      },
      {
        "module": "openai.types.audio.translation_create_params",
        "self_us": 129,
        "cumulative_us": 129,
        "self_ms": 0.129,
        "cumulative_ms": 0.129
      },
      {
        "module": "httpx._config",
        "self_us": 128,
        "cumulative_us": 128,
        "self_ms": 0.128,
        "cumulative_ms": 0.128
      },
      {
        "module": "openai.types.image_create_variation_params",
        "self_us": 127,
        "cumulative_us": 127,
        "self_ms": 0.127,
        "cumulative_ms": 0.127
      },
      {
        "module": "litellm.llms.openai_like.chat",
        "self_us": 80,
        "cumulative_us": 127,
        "self_ms": 0.08,
        "cumulative_ms": 0.127
      },
      {
        "module": "mcp_the_force.adapters.openai.constants",
        "self_us": 127,
        "cumulative_us": 127,
        "self_ms": 0.127,
        "cumulative_ms": 0.127
      },
      {
        "module": "openai.lib._parsing._completions",
        "self_us": 126,
        "cumulative_us": 126,
        "self_ms": 0.126,
        "cumulative_ms": 0.126
      },
      {
        "module": "openai.types.shared_params.function_definition",
        "self_us": 83,
        "cumulative_us": 124,
        "self_ms": 0.083,
        "cumulative_ms": 0.124
      },
      {
        "module": "litellm.llms.openai_like.common_utils",
        "self_us": 123,
        "cumulative_us": 123,
        "self_ms": 0.123,
        "cumulative_ms": 0.123
      },
      {
        "module": "openai.types.responses.response_reasoning_item_param",
        "self_us": 122,
        "cumulative_us": 122,
        "self_ms": 0.122,
        "cumulative_ms": 0.122
      },
      {
        "module": "litellm.llms.openai.completion.utils",
        "self_us": 94,
        "cumulative_us": 122,
        "self_ms": 0.094,
        "cumulative_ms": 0.122
      },
      {
        "module": "mcp_the_force.adapters.openai.client",
        "self_us": 121,
        "cumulative_us": 121,
        "self_ms": 0.121,
        "cumulative_ms": 0.121
      },
      {
        "module": "openai.types.chat.completion_list_params",
        "self_us": 120,
        "cumulative_us": 120,
        "self_ms": 0.12,
        "cumulative_ms": 0.12
      },
      {
        "module": "openai.types.chat.chat_completion_content_part_input_audio_param",
        "self_us": 120,
        "cumulative_us": 120,
        "self_ms": 0.12,
        "cumulative_ms": 0.12
      },
      {
        "module": "openai.types.beta.file_search_tool_param",
        "self_us": 120,
        "cumulative_us": 120,
        "self_ms": 0.12,
        "cumulative_ms": 0.12
      },
      {
        "module": "litellm.llms.openai.cost_calculation",
        "self_us": 94,
        "cumulative_us": 120,
        "self_ms": 0.094,
        "cumulative_ms": 0.12
      },
      {
        "module": "litellm.llms.vertex_ai.vertex_ai_partner_models.anthropic",
        "self_us": 55,
        "cumulative_us": 119,
        "self_ms": 0.055,
        "cumulative_ms": 0.119
      },
      {
        "module": "openai.types.beta.thread_update_params",
        "self_us": 118,
        "cumulative_us": 118,
        "self_ms": 0.118,
        "cumulative_ms": 0.118
      },
      {
        "module": "litellm.anthropic_interface.messages",
        "self_us": 118,
        "cumulative_us": 118,
        "self_ms": 0.118,
        "cumulative_ms": 0.118
      },
      {
        "module": "pydantic.v1.tools",
        "self_us": 117,
        "cumulative_us": 117,
        "self_ms": 0.117,
        "cumulative_ms": 0.117
      },
      {
        "module": "openai.types.beta.assistant_tool_choice_function",
        "self_us": 117,
        "cumulative_us": 117,
        "self_ms": 0.117,
        "cumulative_ms": 0.117
      },
      {
        "module": "openai.types.chat.chat_completion_content_part_image_param",
        "self_us": 116,
        "cumulative_us": 116,
        "self_ms": 0.116,
        "cumulative_ms": 0.116
      },
      {
        "module": "pydantic.v1.annotated_types",
        "self_us": 115,
        "cumulative_us": 115,
        "self_ms": 0.115,
        "cumulative_ms": 0.115
      },
      {
        "module": "openai.types.responses.function_tool_param",
        "self_us": 115,
        "cumulative_us": 115,
        "self_ms": 0.115,
        "cumulative_ms": 0.115
      },
      {
        "module": "litellm.types.integrations.anthropic_cache_control_hook",
        "self_us": 115,
        "cumulative_us": 115,
        "self_ms": 0.115,
        "cumulative_ms": 0.115
      },
      {
        "module": "litellm.llms.openai_like.chat.transformation",
        "self_us": 115,
        "cumulative_us": 115,
        "self_ms": 0.115,
        "cumulative_ms": 0.115
      },
      {
        "module": "openai.types.responses.input_item_list_params",
        "self_us": 113,
        "cumulative_us": 113,
        "self_ms": 0.113,
        "cumulative_ms": 0.113
      },
      {
        "module": "openai._utils._resources_proxy",
        "self_us": 113,
        "cumulative_us": 113,
        "self_ms": 0.113,
        "cumulative_ms": 0.113
      },
      {
        "module": "openai.types.fine_tuning.reinforcement_hyperparameters_param",
        "self_us": 113,
        "cumulative_us": 113,
        "self_ms": 0.113,
        "cumulative_ms": 0.113
      },
      {
        "module": "pydantic_settings.sources.providers.azure",
        "self_us": 113,
        "cumulative_us": 113,
        "self_ms": 0.113,
        "cumulative_ms": 0.113
      },
      {
        "module": "pydantic.v1.version",
        "self_us": 67,
        "cumulative_us": 112,
        "self_ms": 0.067,
        "cumulative_ms": 0.112
      },
      {
        "module": "openai.types.eval_list_params",
        "self_us": 112,
        "cumulative_us": 112,
        "self_ms": 0.112,
        "cumulative_ms": 0.112
      },
      {
        "module": "openai.types.upload_complete_params",
        "self_us": 112,
        "cumulative_us": 112,
        "self_ms": 0.112,
        "cumulative_ms": 0.112
      },
      {
        "module": "openai.types.moderation_image_url_input_param",
        "self_us": 112,
        "cumulative_us": 112,
        "self_ms": 0.112,
        "cumulative_ms": 0.112
      },
      {
        "module": "litellm.llms.anthropic.experimental_pass_through.adapters.streaming_iterator",
        "self_us": 112,
        "cumulative_us": 112,
        "self_ms": 0.112,
        "cumulative_ms": 0.112
      },
      {
        "module": "openai.types.chat.chat_completion_audio_param",
        "self_us": 111,
        "cumulative_us": 111,
        "self_ms": 0.111,
        "cumulative_ms": 0.111
      },
      {
        "module": "openai.types.chat.chat_completion_message_tool_call_param",
        "self_us": 111,
        "cumulative_us": 111,
        "self_ms": 0.111,
        "cumulative_ms": 0.111
      },
      {
        "module": "litellm.llms.openai.chat.o_series_transformation",
        "self_us": 111,
        "cumulative_us": 111,
        "self_ms": 0.111,
        "cumulative_ms": 0.111
      },
      {
        "module": "pydantic_settings.sources.providers.dotenv",
        "self_us": 110,
        "cumulative_us": 110,
        "self_ms": 0.11,
        "cumulative_ms": 0.11
      },
      {
        "module": "httpx._transports.wsgi",
        "self_us": 109,
        "cumulative_us": 109,
        "self_ms": 0.109,
        "cumulative_ms": 0.109
      },
      {
        "module": "openai.types.shared_params.response_format_json_schema",
        "self_us": 109,
        "cumulative_us": 109,
        "self_ms": 0.109,
        "cumulative_ms": 0.109
      },
      {
        "module": "openai.types.responses.tool_choice_mcp_param",
        "self_us": 109,
        "cumulative_us": 109,
        "self_ms": 0.109,
        "cumulative_ms": 0.109
      },
      {
        "module": "openai.types.responses.response_function_tool_call_param",
        "self_us": 108,
        "cumulative_us": 108,
        "self_ms": 0.108,
        "cumulative_ms": 0.108
      },
      {
        "module": "openai.types.vector_store_update_params",
        "self_us": 108,
        "cumulative_us": 108,
        "self_ms": 0.108,
        "cumulative_ms": 0.108
      },
      {
        "module": "pydantic_settings.sources.providers.gcp",
        "self_us": 108,
        "cumulative_us": 108,
        "self_ms": 0.108,
        "cumulative_ms": 0.108
      },
      {
        "module": "litellm.llms.aiohttp_openai.chat",
        "self_us": 71,
        "cumulative_us": 107,
        "self_ms": 0.071,
        "cumulative_ms": 0.107
      },
      {
        "module": "litellm.llms.openai.completion.transformation",
        "self_us": 107,
        "cumulative_us": 107,
        "self_ms": 0.107,
        "cumulative_ms": 0.107
      },
      {
        "module": "pydantic._internal._validate_call",
        "self_us": 107,
        "cumulative_us": 107,
        "self_ms": 0.107,
        "cumulative_ms": 0.107
      },
      {
        "module": "openai.types.fine_tuning.job_list_params",
        "self_us": 105,
        "cumulative_us": 105,
        "self_ms": 0.105,
        "cumulative_ms": 0.105
      },
      {
        "module": "openai.types.chat.chat_completion_content_part_text_param",
        "self_us": 103,
        "cumulative_us": 103,
        "self_ms": 0.103,
        "cumulative_ms": 0.103
      },
      {
        "module": "openai.types.upload_create_params",
        "self_us": 103,
        "cumulative_us": 103,
        "self_ms": 0.103,
        "cumulative_ms": 0.103
      },
      {
        "module": "openai.types.beta.threads.image_url_param",
        "self_us": 103,
        "cumulative_us": 103,
        "self_ms": 0.103,
        "cumulative_ms": 0.103
      },
      {
        "module": "litellm.llms.openai.image_variations.handler",
        "self_us": 103,
        "cumulative_us": 103,
        "self_ms": 0.103,
        "cumulative_ms": 0.103
      },
      {
        "module": "openai.types.responses.response_input_image_param",
        "self_us": 102,
        "cumulative_us": 102,
        "self_ms": 0.102,
        "cumulative_ms": 0.102
      },
      {
        "module": "mcp_the_force.adapters.anthropic.blueprints",
        "self_us": 102,
        "cumulative_us": 102,
        "self_ms": 0.102,
        "cumulative_ms": 0.102
      },
      {
        "module": "openai._utils._proxy",
        "self_us": 101,
        "cumulative_us": 101,
        "self_ms": 0.101,
        "cumulative_ms": 0.101
      },
      {
        "module": "openai.lib._old_api",
        "self_us": 100,
        "cumulative_us": 100,
        "self_ms": 0.1,
        "cumulative_ms": 0.1
      },
      {
        "module": "openai.types.beta.threads.runs.step_list_params",
        "self_us": 99,
        "cumulative_us": 99,
        "self_ms": 0.099,
        "cumulative_ms": 0.099
      },
      {
        "module": "openai.types.beta.threads.message_list_params",
        "self_us": 99,
        "cumulative_us": 99,
        "self_ms": 0.099,
        "cumulative_ms": 0.099
      },
      {
        "module": "pydantic._internal._dataclasses",
        "self_us": 99,
        "cumulative_us": 99,
        "self_ms": 0.099,
        "cumulative_ms": 0.099
      },
      {
        "module": "pydantic_settings.sources.providers.env",
        "self_us": 99,
        "cumulative_us": 99,
        "self_ms": 0.099,
        "cumulative_ms": 0.099
      },
      {
        "module": "openai.types.chat.chat_completion_system_message_param",
        "self_us": 98,
        "cumulative_us": 98,
        "self_ms": 0.098,
        "cumulative_ms": 0.098
      },
      {
        "module": "httpx._utils",
        "self_us": 97,
        "cumulative_us": 97,
        "self_ms": 0.097,
        "cumulative_ms": 0.097
      },
      {
        "module": "openai.types.vector_store_list_params",
        "self_us": 97,
        "cumulative_us": 97,
        "self_ms": 0.097,
        "cumulative_ms": 0.097
      },
      {
        "module": "litellm.llms.openai.transcriptions.handler",
        "self_us": 97,
        "cumulative_us": 97,
        "self_ms": 0.097,
        "cumulative_ms": 0.097
      },
      {
        "module": "pydantic.annotated_handlers",
        "self_us": 96,
        "cumulative_us": 96,
        "self_ms": 0.096,
        "cumulative_ms": 0.096
      },
      {
        "module": "openai.types.chat.chat_completion_function_message_param",
        "self_us": 96,
        "cumulative_us": 96,
        "self_ms": 0.096,
        "cumulative_ms": 0.096
      },
      {
        "module": "openai.types.fine_tuning.dpo_hyperparameters_param",
        "self_us": 96,
        "cumulative_us": 96,
        "self_ms": 0.096,
        "cumulative_ms": 0.096
      },
      {
        "module": "openai.types.graders.string_check_grader_param",
        "self_us": 95,
        "cumulative_us": 95,
        "self_ms": 0.095,
        "cumulative_ms": 0.095
      },
      {
        "module": "openai.types.beta.function_tool_param",
        "self_us": 95,
        "cumulative_us": 95,
        "self_ms": 0.095,
        "cumulative_ms": 0.095
      },
      {
        "module": "litellm.llms.openai.completion.handler",
        "self_us": 95,
        "cumulative_us": 95,
        "self_ms": 0.095,
        "cumulative_ms": 0.095
      },
      {
        "module": "openai.types.chat.chat_completion_developer_message_param",
        "self_us": 94,
        "cumulative_us": 94,
        "self_ms": 0.094,
        "cumulative_ms": 0.094
      },
      {
        "module": "openai.types.responses.response_includable",
        "self_us": 94,
        "cumulative_us": 94,
        "self_ms": 0.094,
        "cumulative_ms": 0.094
      },
      {
        "module": "openai.types.responses.response_input_file_param",
        "self_us": 93,
        "cumulative_us": 93,
        "self_ms": 0.093,
        "cumulative_ms": 0.093
      },
      {
        "module": "openai.types.responses.response_format_text_json_schema_config_param",
        "self_us": 92,
        "cumulative_us": 92,
        "self_ms": 0.092,
        "cumulative_ms": 0.092
      },
      {
        "module": "pydantic._internal._serializers",
        "self_us": 91,
        "cumulative_us": 91,
        "self_ms": 0.091,
        "cumulative_ms": 0.091
      },
      {
        "module": "openai.types.chat.chat_completion_tool_param",
        "self_us": 91,
        "cumulative_us": 91,
        "self_ms": 0.091,
        "cumulative_ms": 0.091
      },
      {
        "module": "openai.types.chat.completion_update_params",
        "self_us": 91,
        "cumulative_us": 91,
        "self_ms": 0.091,
        "cumulative_ms": 0.091
      },
      {
        "module": "openai.types.beta.threads.run_list_params",
        "self_us": 91,
        "cumulative_us": 91,
        "self_ms": 0.091,
        "cumulative_ms": 0.091
      },
      {
        "module": "pydantic_settings.exceptions",
        "self_us": 91,
        "cumulative_us": 91,
        "self_ms": 0.091,
        "cumulative_ms": 0.091
      },
      {
        "module": "openai.types.graders.text_similarity_grader_param",
        "self_us": 90,
        "cumulative_us": 90,
        "self_ms": 0.09,
        "cumulative_ms": 0.09
      },
      {
        "module": "mcp_the_force.adapters.anthropic.params",
        "self_us": 90,
        "cumulative_us": 90,
        "self_ms": 0.09,
        "cumulative_ms": 0.09
      },
      {
        "module": "openai.types.shared_params.reasoning",
        "self_us": 89,
        "cumulative_us": 89,
        "self_ms": 0.089,
        "cumulative_ms": 0.089
      },
      {
        "module": "tiktoken.load",
        "self_us": 89,
        "cumulative_us": 89,
        "self_ms": 0.089,
        "cumulative_ms": 0.089
      },
      {
        "module": "openai._utils._typing",
        "self_us": 88,
        "cumulative_us": 88,
        "self_ms": 0.088,
        "cumulative_ms": 0.088
      },
      {
        "module": "openai.types.moderation_text_input_param",
        "self_us": 88,
        "cumulative_us": 88,
        "self_ms": 0.088,
        "cumulative_ms": 0.088
      },
      {
        "module": "litellm.llms.anthropic.experimental_pass_through.messages",
        "self_us": 53,
        "cumulative_us": 88,
        "self_ms": 0.053,
        "cumulative_ms": 0.088
      },
      {
        "module": "openai.types.beta.threads.text_content_block_param",
        "self_us": 87,
        "cumulative_us": 87,
        "self_ms": 0.087,
        "cumulative_ms": 0.087
      },
      {
        "module": "openai.types.batch_create_params",
        "self_us": 86,
        "cumulative_us": 86,
        "self_ms": 0.086,
        "cumulative_ms": 0.086
      },
      {
        "module": "openai.types.beta.threads.run_status",
        "self_us": 86,
        "cumulative_us": 86,
        "self_ms": 0.086,
        "cumulative_ms": 0.086
      },
      {
        "module": "openai.types.beta.threads.image_url_content_block_param",
        "self_us": 86,
        "cumulative_us": 86,
        "self_ms": 0.086,
        "cumulative_ms": 0.086
      },
      {
        "module": "openai.types.beta.assistant_response_format_option_param",
        "self_us": 86,
        "cumulative_us": 86,
        "self_ms": 0.086,
        "cumulative_ms": 0.086
      },
      {
        "module": "openai.types.responses.response_computer_tool_call_output_screenshot_param",
        "self_us": 85,
        "cumulative_us": 85,
        "self_ms": 0.085,
        "cumulative_ms": 0.085
      },
      {
        "module": "openai.types.static_file_chunking_strategy_param",
        "self_us": 85,
        "cumulative_us": 85,
        "self_ms": 0.085,
        "cumulative_ms": 0.085
      },
      {
        "module": "openai.types.beta.threads.runs.step_retrieve_params",
        "self_us": 85,
        "cumulative_us": 85,
        "self_ms": 0.085,
        "cumulative_ms": 0.085
      },
      {
        "module": "openai.types.beta.threads.image_file_content_block_param",
        "self_us": 85,
        "cumulative_us": 85,
        "self_ms": 0.085,
        "cumulative_ms": 0.085
      },
      {
        "module": "pydantic_settings.sources.providers.secrets",
        "self_us": 85,
        "cumulative_us": 85,
        "self_ms": 0.085,
        "cumulative_ms": 0.085
      },
      {
        "module": "pydantic._internal",
        "self_us": 84,
        "cumulative_us": 84,
        "self_ms": 0.084,
        "cumulative_ms": 0.084
      },
      {
        "module": "openai.types.shared.metadata",
        "self_us": 84,
        "cumulative_us": 84,
        "self_ms": 0.084,
        "cumulative_ms": 0.084
      },
      {
        "module": "openai.types.file_list_params",
        "self_us": 84,
        "cumulative_us": 84,
        "self_ms": 0.084,
        "cumulative_ms": 0.084
      },
      {
        "module": "openai.types.shared_params.comparison_filter",
        "self_us": 84,
        "cumulative_us": 84,
        "self_ms": 0.084,
        "cumulative_ms": 0.084
      },
      {
        "module": "openai.types.chat.chat_completion_named_tool_choice_param",
        "self_us": 84,
        "cumulative_us": 84,
        "self_ms": 0.084,
        "cumulative_ms": 0.084
      },
      {
        "module": "openai.types.shared_params.metadata",
        "self_us": 83,
        "cumulative_us": 83,
        "self_ms": 0.083,
        "cumulative_ms": 0.083
      },
      {
        "module": "openai.types.chat.chat_completion_prediction_content_param",
        "self_us": 83,
        "cumulative_us": 83,
        "self_ms": 0.083,
        "cumulative_ms": 0.083
      },
      {
        "module": "openai.types.graders.python_grader_param",
        "self_us": 83,
        "cumulative_us": 83,
        "self_ms": 0.083,
        "cumulative_ms": 0.083
      },
      {
        "module": "openai.types.eval_update_params",
        "self_us": 83,
        "cumulative_us": 83,
        "self_ms": 0.083,
        "cumulative_ms": 0.083
      },
      {
        "module": "openai.types.responses.response_input_text_param",
        "self_us": 82,
        "cumulative_us": 82,
        "self_ms": 0.082,
        "cumulative_ms": 0.082
      },
      {
        "module": "openai.lib._pydantic",
        "self_us": 81,
        "cumulative_us": 81,
        "self_ms": 0.081,
        "cumulative_ms": 0.081
      },
      {
        "module": "openai.types.fine_tuning.supervised_hyperparameters_param",
        "self_us": 81,
        "cumulative_us": 81,
        "self_ms": 0.081,
        "cumulative_ms": 0.081
      },
      {
        "module": "openai.types.fine_tuning.job_list_events_params",
        "self_us": 81,
        "cumulative_us": 81,
        "self_ms": 0.081,
        "cumulative_ms": 0.081
      },
      {
        "module": "openai.types.responses.tool_choice_options",
        "self_us": 79,
        "cumulative_us": 79,
        "self_ms": 0.079,
        "cumulative_ms": 0.079
      },
      {
        "module": "openai.types.beta.threads.run_update_params",
        "self_us": 79,
        "cumulative_us": 79,
        "self_ms": 0.079,
        "cumulative_ms": 0.079
      },
      {
        "module": "litellm.llms.bedrock.chat.invoke_transformations.anthropic_claude3_transformation",
        "self_us": 79,
        "cumulative_us": 79,
        "self_ms": 0.079,
        "cumulative_ms": 0.079
      },
      {
        "module": "openai.types.responses.response_status",
        "self_us": 78,
        "cumulative_us": 78,
        "self_ms": 0.078,
        "cumulative_ms": 0.078
      },
      {
        "module": "openai.types.chat.chat_completion_role",
        "self_us": 78,
        "cumulative_us": 78,
        "self_ms": 0.078,
        "cumulative_ms": 0.078
      },
      {
        "module": "openai.types.responses.response_input_content_param",
        "self_us": 78,
        "cumulative_us": 78,
        "self_ms": 0.078,
        "cumulative_ms": 0.078
      },
      {
        "module": "openai.types.beta.assistant_response_format_option",
        "self_us": 78,
        "cumulative_us": 78,
        "self_ms": 0.078,
        "cumulative_ms": 0.078
      },
      {
        "module": "litellm.llms.bedrock.chat.invoke_transformations.anthropic_claude2_transformation",
        "self_us": 78,
        "cumulative_us": 78,
        "self_ms": 0.078,
        "cumulative_ms": 0.078
      },
      {
        "module": "openai.types.responses.response_output_refusal_param",
        "self_us": 77,
        "cumulative_us": 77,
        "self_ms": 0.077,
        "cumulative_ms": 0.077
      },
      {
        "module": "openai.types.container_list_params",
        "self_us": 77,
        "cumulative_us": 77,
        "self_ms": 0.077,
        "cumulative_ms": 0.077
      },
      {
        "module": "openai.types.auto_file_chunking_strategy_param",
        "self_us": 77,
        "cumulative_us": 77,
        "self_ms": 0.077,
        "cumulative_ms": 0.077
      },
      {
        "module": "openai.types.beta.assistant_list_params",
        "self_us": 77,
        "cumulative_us": 77,
        "self_ms": 0.077,
        "cumulative_ms": 0.077
      },
      {
        "module": "openai.types.audio.speech_model",
        "self_us": 77,
        "cumulative_us": 77,
        "self_ms": 0.077,
        "cumulative_ms": 0.077
      },
      {
        "module": "pydantic_settings.sources.providers.json",
        "self_us": 77,
        "cumulative_us": 77,
        "self_ms": 0.077,
        "cumulative_ms": 0.077
      },
      {
        "module": "openai.types.responses.response_input_content",
        "self_us": 76,
        "cumulative_us": 76,
        "self_ms": 0.076,
        "cumulative_ms": 0.076
      },
      {
        "module": "litellm.llms.custom_httpx.async_client_cleanup",
        "self_us": 75,
        "cumulative_us": 75,
        "self_ms": 0.075,
        "cumulative_ms": 0.075
      },
      {
        "module": "tiktoken_ext",
        "self_us": 75,
        "cumulative_us": 75,
        "self_ms": 0.075,
        "cumulative_ms": 0.075
      },
      {
        "module": "httpx.__version__",
        "self_us": 74,
        "cumulative_us": 74,
        "self_ms": 0.074,
        "cumulative_ms": 0.074
      },
      {
        "module": "openai.types.chat.chat_completion_content_part_refusal_param",
        "self_us": 74,
        "cumulative_us": 74,
        "self_ms": 0.074,
        "cumulative_ms": 0.074
      },
      {
        "module": "openai.types.responses.tool_choice_function_param",
        "self_us": 74,
        "cumulative_us": 74,
        "self_ms": 0.074,
        "cumulative_ms": 0.074
      },
      {
        "module": "openai.types.file_create_params",
        "self_us": 74,
        "cumulative_us": 74,
        "self_ms": 0.074,
        "cumulative_ms": 0.074
      },
      {
        "module": "openai.types.beta.threads.image_file_param",
        "self_us": 74,
        "cumulative_us": 74,
        "self_ms": 0.074,
        "cumulative_ms": 0.074
      },
      {
        "module": "litellm.llms.openai.chat.gpt_audio_transformation",
        "self_us": 74,
        "cumulative_us": 74,
        "self_ms": 0.074,
        "cumulative_ms": 0.074
      },
      {
        "module": "litellm.llms.openai.transcriptions.gpt_transformation",
        "self_us": 73,
        "cumulative_us": 73,
        "self_ms": 0.073,
        "cumulative_ms": 0.073
      },
      {
        "module": "openai._files",
        "self_us": 72,
        "cumulative_us": 72,
        "self_ms": 0.072,
        "cumulative_ms": 0.072
      },
      {
        "module": "openai.types.chat.chat_completion_modality",
        "self_us": 72,
        "cumulative_us": 72,
        "self_ms": 0.072,
        "cumulative_ms": 0.072
      },
      {
        "module": "openai.types.chat.chat_completion_stream_options_param",
        "self_us": 72,
        "cumulative_us": 72,
        "self_ms": 0.072,
        "cumulative_ms": 0.072
      },
      {
        "module": "openai.types.beta.code_interpreter_tool_param",
        "self_us": 72,
        "cumulative_us": 72,
        "self_ms": 0.072,
        "cumulative_ms": 0.072
      },
      {
        "module": "litellm.llms.anthropic.experimental_pass_through.messages.utils",
        "self_us": 72,
        "cumulative_us": 72,
        "self_ms": 0.072,
        "cumulative_ms": 0.072
      },
      {
        "module": "openai.types.shared.responses_model",
        "self_us": 71,
        "cumulative_us": 71,
        "self_ms": 0.071,
        "cumulative_ms": 0.071
      },
      {
        "module": "openai.types.audio_model",
        "self_us": 71,
        "cumulative_us": 71,
        "self_ms": 0.071,
        "cumulative_ms": 0.071
      },
      {
        "module": "openai.types.chat.chat_completion_function_call_option_param",
        "self_us": 71,
        "cumulative_us": 71,
        "self_ms": 0.071,
        "cumulative_ms": 0.071
      },
      {
        "module": "mcp.shared._httpx_utils",
        "self_us": 71,
        "cumulative_us": 71,
        "self_ms": 0.071,
        "cumulative_ms": 0.071
      },
      {
        "module": "pydantic.plugin._loader",
        "self_us": 70,
        "cumulative_us": 70,
        "self_ms": 0.07,
        "cumulative_ms": 0.07
      },
      {
        "module": "openai.types.batch_list_params",
        "self_us": 69,
        "cumulative_us": 69,
        "self_ms": 0.069,
        "cumulative_ms": 0.069
      },
      {
        "module": "openai.types.shared_params.response_format_json_object",
        "self_us": 69,
        "cumulative_us": 69,
        "self_ms": 0.069,
        "cumulative_ms": 0.069
      },
      {
        "module": "openai.version",
        "self_us": 69,
        "cumulative_us": 69,
        "self_ms": 0.069,
        "cumulative_ms": 0.069
      },
      {
        "module": "openai.types.beta.threads.message_update_params",
        "self_us": 69,
        "cumulative_us": 69,
        "self_ms": 0.069,
        "cumulative_ms": 0.069
      },
      {
        "module": "litellm.llms.base_llm.anthropic_messages",
        "self_us": 69,
        "cumulative_us": 69,
        "self_ms": 0.069,
        "cumulative_ms": 0.069
      },
      {
        "module": "openai.types.responses.tool_choice_types_param",
        "self_us": 68,
        "cumulative_us": 68,
        "self_ms": 0.068,
        "cumulative_ms": 0.068
      },
      {
        "module": "litellm.llms.anthropic.batches",
        "self_us": 68,
        "cumulative_us": 68,
        "self_ms": 0.068,
        "cumulative_ms": 0.068
      },
      {
        "module": "openai.types.shared.reasoning_effort",
        "self_us": 67,
        "cumulative_us": 67,
        "self_ms": 0.067,
        "cumulative_ms": 0.067
      },
      {
        "module": "openai.types.shared_params.response_format_text",
        "self_us": 67,
        "cumulative_us": 67,
        "self_ms": 0.067,
        "cumulative_ms": 0.067
      },
      {
        "module": "pydantic_settings.sources.providers.yaml",
        "self_us": 67,
        "cumulative_us": 67,
        "self_ms": 0.067,
        "cumulative_ms": 0.067
      },
      {
        "module": "pydantic.json",
        "self_us": 67,
        "cumulative_us": 67,
        "self_ms": 0.067,
        "cumulative_ms": 0.067
      },
      {
        "module": "openai.types.audio.translation_create_response",
        "self_us": 66,
        "cumulative_us": 66,
        "self_ms": 0.066,
        "cumulative_ms": 0.066
      },
      {
        "module": "pydantic_settings.utils",
        "self_us": 66,
        "cumulative_us": 66,
        "self_ms": 0.066,
        "cumulative_ms": 0.066
      },
      {
        "module": "openai.types.audio.transcription_create_response",
        "self_us": 65,
        "cumulative_us": 65,
        "self_ms": 0.065,
        "cumulative_ms": 0.065
      },
      {
        "module": "openai.types.beta.assistant_tool_choice_function_param",
        "self_us": 64,
        "cumulative_us": 64,
        "self_ms": 0.064,
        "cumulative_ms": 0.064
      },
      {
        "module": "openai.types.audio.transcription_include",
        "self_us": 64,
        "cumulative_us": 64,
        "self_ms": 0.064,
        "cumulative_ms": 0.064
      },
      {
        "module": "pydantic_settings.sources.providers.toml",
        "self_us": 64,
        "cumulative_us": 64,
        "self_ms": 0.064,
        "cumulative_ms": 0.064
      },
      {
        "module": "httpx_sse._models",
        "self_us": 63,
        "cumulative_us": 63,
        "self_ms": 0.063,
        "cumulative_ms": 0.063
      },
      {
        "module": "httpx_sse._exceptions",
        "self_us": 63,
        "cumulative_us": 63,
        "self_ms": 0.063,
        "cumulative_ms": 0.063
      },
      {
        "module": "openai._utils._streams",
        "self_us": 61,
        "cumulative_us": 61,
        "self_ms": 0.061,
        "cumulative_ms": 0.061
      },
      {
        "module": "openai.types.audio_response_format",
        "self_us": 61,
        "cumulative_us": 61,
        "self_ms": 0.061,
        "cumulative_ms": 0.061
      },
      {
        "module": "pydantic_settings.version",
        "self_us": 61,
        "cumulative_us": 61,
        "self_ms": 0.061,
        "cumulative_ms": 0.061
      },
      {
        "module": "openai.types.chat_model",
        "self_us": 60,
        "cumulative_us": 60,
        "self_ms": 0.06,
        "cumulative_ms": 0.06
      },
      {
        "module": "openai.types.shared_params.responses_model",
        "self_us": 59,
        "cumulative_us": 59,
        "self_ms": 0.059,
        "cumulative_ms": 0.059
      },
      {
        "module": "openai.types.file_purpose",
        "self_us": 58,
        "cumulative_us": 58,
        "self_ms": 0.058,
        "cumulative_ms": 0.058
      },
      {
        "module": "openai.types.embedding_model",
        "self_us": 58,
        "cumulative_us": 58,
        "self_ms": 0.058,
        "cumulative_ms": 0.058
      },
      {
        "module": "openai.types.beta.threads.runs.run_step_include",
        "self_us": 58,
        "cumulative_us": 58,
        "self_ms": 0.058,
        "cumulative_ms": 0.058
      },
      {
        "module": "openai._utils._reflection",
        "self_us": 57,
        "cumulative_us": 57,
        "self_ms": 0.057,
        "cumulative_ms": 0.057
      },
      {
        "module": "openai._version",
        "self_us": 57,
        "cumulative_us": 57,
        "self_ms": 0.057,
        "cumulative_ms": 0.057
      },
      {
        "module": "openai.types.chat.chat_completion_reasoning_effort",
        "self_us": 56,
        "cumulative_us": 56,
        "self_ms": 0.056,
        "cumulative_ms": 0.056
      },
      {
        "module": "openai._constants",
        "self_us": 55,
        "cumulative_us": 55,
        "self_ms": 0.055,
        "cumulative_ms": 0.055
      },
      {
        "module": "openai.types.image_model",
        "self_us": 54,
        "cumulative_us": 54,
        "self_ms": 0.054,
        "cumulative_ms": 0.054
      },
      {
        "module": "openai.types.moderation_model",
        "self_us": 53,
        "cumulative_us": 53,
        "self_ms": 0.053,
        "cumulative_ms": 0.053
      },
      {
        "module": "httpx_aiohttp",
        "self_us": 52,
        "cumulative_us": 52,
        "self_ms": 0.052,
        "cumulative_ms": 0.052
      },
      {
        "module": "pydantic._internal._internal_dataclass",
        "self_us": 50,
        "cumulative_us": 50,
        "self_ms": 0.05,
        "cumulative_ms": 0.05
      },
      {
        "module": "openai.types.shared_params.chat_model",
        "self_us": 50,
        "cumulative_us": 50,
        "self_ms": 0.05,
        "cumulative_ms": 0.05
      },
      {
        "module": "openai.types.fine_tuning.fine_tuning_job_integration",
        "self_us": 48,
        "cumulative_us": 48,
        "self_ms": 0.048,
        "cumulative_ms": 0.048
      },
      {
        "module": "litellm.llms.openai_like",
        "self_us": 48,
        "cumulative_us": 48,
        "self_ms": 0.048,
        "cumulative_ms": 0.048
      },
      {
        "module": "openai.types.file_content",
        "self_us": 47,
        "cumulative_us": 47,
        "self_ms": 0.047,
        "cumulative_ms": 0.047
      },
      {
        "module": "openai.types.shared.function_parameters",
        "self_us": 46,
        "cumulative_us": 46,
        "self_ms": 0.046,
        "cumulative_ms": 0.046
      },
      {
        "module": "openai.types.shared_params.reasoning_effort",
        "self_us": 45,
        "cumulative_us": 45,
        "self_ms": 0.045,
        "cumulative_ms": 0.045
      },
      {
        "module": "openai.types.shared_params.function_parameters",
        "self_us": 41,
        "cumulative_us": 41,
        "self_ms": 0.041,
        "cumulative_ms": 0.041
      },
      {
        "module": "litellm.llms.openai.fine_tuning",
        "self_us": 41,
        "cumulative_us": 41,
        "self_ms": 0.041,
        "cumulative_ms": 0.041
      },
      {
        "module": "litellm.llms.openai.image_variations",
        "self_us": 37,
        "cumulative_us": 37,
        "self_ms": 0.037,
        "cumulative_ms": 0.037
      },
      {
        "module": "litellm.llms.openai.transcriptions",
        "self_us": 37,
        "cumulative_us": 37,
        "self_ms": 0.037,
        "cumulative_ms": 0.037
      },
      {
        "module": "litellm.llms.openai.chat",
        "self_us": 36,
        "cumulative_us": 36,
        "self_ms": 0.036,
        "cumulative_ms": 0.036
      },
      {
        "module": "litellm.llms.aiohttp_openai",
        "self_us": 36,
        "cumulative_us": 36,
        "self_ms": 0.036,
        "cumulative_ms": 0.036
      },
      {
        "module": "litellm.llms.anthropic.experimental_pass_through",
        "self_us": 36,
        "cumulative_us": 36,
        "self_ms": 0.036,
        "cumulative_ms": 0.036
      },
      {
        "module": "litellm.llms.anthropic.completion",
        "self_us": 34,
        "cumulative_us": 34,
        "self_ms": 0.034,
        "cumulative_ms": 0.034
      },
      {
        "module": "litellm.types.llms.anthropic_messages",
        "self_us": 33,
        "cumulative_us": 33,
        "self_ms": 0.033,
        "cumulative_ms": 0.033
      },
      {
        "module": "litellm.llms.openai.realtime",
        "self_us": 33,
        "cumulative_us": 33,
        "self_ms": 0.033,
        "cumulative_ms": 0.033
      },
      {
        "module": "litellm.llms.openai.responses",
        "self_us": 32,
        "cumulative_us": 32,
        "self_ms": 0.032,
        "cumulative_ms": 0.032
      },
      {
        "module": "litellm.llms.openai_like.embedding",
        "self_us": 32,
        "cumulative_us": 32,
        "self_ms": 0.032,
        "cumulative_ms": 0.032
      },
      {
        "module": "litellm.llms.openai.completion",
        "self_us": 28,
        "cumulative_us": 28,
        "self_ms": 0.028,
        "cumulative_ms": 0.028
      },
      {
        "module": "litellm.llms.openai",
        "self_us": 27,
        "cumulative_us": 27,
        "self_ms": 0.027,
        "cumulative_ms": 0.027
      }
    ],
    "all_imports": []
  },
  "memory_profile": {
    "baseline_mb": 0.0,
    "autogen_mb": 91.0820484161377,
    "register_mb": 112.63921546936035,
    "final_mb": 112.5212631225586,
    "peak_mb": 112.6420783996582,
    "autogen_delta_mb": 91.0820484161377,
    "register_delta_mb": 21.557167053222656
  },
  "bottlenecks": [
    {
      "rank": 1,
      "category": "Single Heavy Import",
      "impact_ms": 752.542,
      "description": "Heavy import chain in mcp_the_force.tools",
      "modules": [
        "mcp_the_force.tools"
      ],
      "optimization": "Analyze and optimize this specific import chain"
    },
    {
      "rank": 2,
      "category": "Heavy Dependencies",
      "impact_ms": 202.19,
      "description": "Loading heavy ML/API dependencies",
      "modules": [
        "litellm.llms.custom_httpx.http_handler",
        "openai._models",
        "openai",
        "openai.types",
        "openai.types.batch"
      ],
      "optimization": "Defer import of heavy dependencies until first use"
    }
  ],
  "recommendations": [
    "\ud83d\udd0d INVESTIGATE: Optimize mcp_the_force.tools",
    "   - Profile this specific module's import chain",
    "   - Look for unnecessary initialization at import time",
    "   - Expected improvement: 753ms \u2192 ~25ms",
    "\u26a1 HIGH: Defer heavy dependency imports",
    "   - Move OpenAI/Google SDK imports inside functions",
    "   - Use import guards for optional dependencies",
    "   - Expected improvement: 202ms \u2192 ~20ms",
    "",
    "\ud83d\udccb GENERAL OPTIMIZATIONS:",
    "   - Move Ollama initialization to background task",
    "   - Implement conditional adapter loading based on config",
    "   - Cache tool registration results",
    "   - Use import-time feature flags"
  ]
}