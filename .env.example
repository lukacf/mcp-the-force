# MCP Second-Brain Server Configuration

# Server Settings
HOST=127.0.0.1
PORT=8000
LOG_LEVEL=INFO

# OpenAI Configuration (required for o3, o3-pro, gpt-4.1 models)
OPENAI_API_KEY=sk-your-openai-api-key-here

# Google Vertex AI Configuration (required for Gemini models)
VERTEX_PROJECT=your-gcp-project-id
VERTEX_LOCATION=us-central1
# Note: Also run 'gcloud auth application-default login' for authentication

# Context Management
MAX_INLINE_TOKENS=12000  # Files under this token count are inlined directly
DEFAULT_TEMPERATURE=0.2  # Default creativity/randomness for AI responses

# Performance Limits
# These are set in fs.py constants:
# - MAX_FILE_SIZE=500KB per file
# - MAX_TOTAL_SIZE=50MB total gathered files